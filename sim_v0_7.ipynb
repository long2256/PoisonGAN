{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/long2256/PoisonGAN/blob/main/sim_v0_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxTwNkEtU6tr"
      },
      "source": [
        "# Environment Setup\n",
        "\n",
        "To start working with Flower, very little is required once you have activated your Python environment (e.g. via `conda`, `virtualenv`, `pyenv`, etc). If you are running this code on Colab, there is really nothing to do except to install Flower and other dependencies. The steps below have been verified to run in Colab.\n",
        "\n",
        "## Installing Flower\n",
        "\n",
        "You can install flower very conveniently from `pip`:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "atIwGIZfJbTY"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWcgETZxU6tt",
        "outputId": "a781d41b-8c43-4aea-a42f-ee63dc507182"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.2/219.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flwr_datasets[vision]\n",
            "  Downloading flwr_datasets-0.0.2-py3-none-any.whl (22 kB)\n",
            "Collecting datasets<3.0.0,>=2.14.3 (from flwr_datasets[vision])\n",
            "  Downloading datasets-2.16.0-py3-none-any.whl (507 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from flwr_datasets[vision]) (1.23.5)\n",
            "Requirement already satisfied: pillow>=6.2.1 in /usr/local/lib/python3.10/dist-packages (from flwr_datasets[vision]) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (3.13.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (10.0.1)\n",
            "Collecting pyarrow-hotfix (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision])\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision])\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (3.4.1)\n",
            "Collecting multiprocess (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision])\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (3.9.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (0.19.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (1.16.0)\n",
            "Installing collected packages: pyarrow-hotfix, dill, multiprocess, datasets, flwr_datasets\n",
            "Successfully installed datasets-2.16.0 dill-0.3.7 flwr_datasets-0.0.2 multiprocess-0.70.15 pyarrow-hotfix-0.6\n"
          ]
        }
      ],
      "source": [
        "# depending on your shell, you might need to add `\\` before `[` and `]`.\n",
        "!pip install -q flwr[simulation]\n",
        "!pip install flwr_datasets[vision]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fN9vsH9gU6tu",
        "outputId": "2d69dddc-5558-4510-8653-7b62851a899c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "O37lBkTdU6tw",
        "outputId": "932c52e2-146e-4906-c4a2-c8d04841e526",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 110733026.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 91011039.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 42029884.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 22679200.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import Compose, ToTensor, Resize\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "\n",
        "def devide_dataset(dataset, dataloader, num_classes: int):\n",
        "    for i in range(num_classes):\n",
        "        # Get indices of samples for each class\n",
        "        indices = [idx for idx, (img, label) in enumerate(dataset) if label == i]\n",
        "        # Divide the indices into 3 subsets\n",
        "        subset_size = len(indices) // 3\n",
        "        subset_indices = [indices[j * subset_size: (j + 1) * subset_size] for j in range(3)]\n",
        "        # Create DataLoader for each subset and add to trainloaders\n",
        "        for subset_idx in subset_indices:\n",
        "            sampler = SubsetRandomSampler(subset_idx)\n",
        "            loader = DataLoader(dataset, sampler=sampler)\n",
        "            dataloader.append(loader)\n",
        "    return dataloader\n",
        "\n",
        "def prepare_dataset():\n",
        "    # Define transforms\n",
        "    transforms = Compose([\n",
        "        ToTensor(),\n",
        "        Resize((64, 64), antialias=False)\n",
        "    ])\n",
        "    trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transforms)\n",
        "    testset = datasets.MNIST(root='./data', train=False, download=True, transform=transforms)\n",
        "    testloader = DataLoader(testset)\n",
        "    trainloaders = []\n",
        "    trainloader = devide_dataset(trainset, trainloaders, 10)\n",
        "\n",
        "\n",
        "    return trainset, trainloaders, testset, testloader\n",
        "\n",
        "trainset, trainloader, testset, testloader = prepare_dataset()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Subset\n",
        "import matplotlib.pyplot as plt\n",
        "def visualise_histogram(trainloader, loader_idx_list):\n",
        "    for idx in loader_idx_list:\n",
        "        subset_indices = trainloader[idx].sampler.indices\n",
        "        train_partition = Subset(trainloader[idx].dataset, subset_indices)\n",
        "\n",
        "        # Count data points\n",
        "        partition_indices = train_partition.indices\n",
        "        print(f\"Number of images: {len(partition_indices)}\")\n",
        "\n",
        "        # Visualize histogram\n",
        "        plt.hist(train_partition.dataset.targets[partition_indices], bins=10)\n",
        "        plt.grid()\n",
        "        plt.xticks(range(10))\n",
        "        plt.xlabel(\"Label\")\n",
        "        plt.ylabel(\"Number of images\")\n",
        "        plt.title(\"Class labels distribution for MNIST\")\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "Fw8PD0Hd0Lbo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ae0hFajz4YiQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QiodpnqLU6tv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=4, stride=2, padding=1)\n",
        "        self.leaky1 = nn.LeakyReLU()\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=4, stride=2, padding=1)\n",
        "        self.leaky2 = nn.LeakyReLU()\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=4, stride=2, padding=1)\n",
        "        self.leaky3 = nn.LeakyReLU()\n",
        "\n",
        "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.leaky4 = nn.LeakyReLU()\n",
        "\n",
        "        self.conv5 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.leaky5 = nn.LeakyReLU()\n",
        "\n",
        "        self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.leaky6 = nn.LeakyReLU()\n",
        "\n",
        "        self.avgpool = nn.AvgPool2d(2, stride=2)\n",
        "\n",
        "        self.fc = nn.Linear(4 * 4 * 128, 10)  # 10 classes for MNIST\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.leaky1(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.leaky2(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.leaky3(x)\n",
        "\n",
        "        x = self.conv4(x)\n",
        "        x = self.leaky4(x)\n",
        "\n",
        "        x = self.conv5(x)\n",
        "        x = self.leaky5(x)\n",
        "\n",
        "        x = self.conv6(x)\n",
        "        x = self.leaky6(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten the output\n",
        "        x = self.fc(x)\n",
        "        x = self.softmax(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=4, stride=2, padding=1)\n",
        "        self.leaky1 = nn.LeakyReLU()\n",
        "        self.dropout = nn.Dropout()\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=4, stride=2, padding=1)\n",
        "        self.batchnorm1 = nn.BatchNorm2d(64)\n",
        "        self.leaky2 = nn.LeakyReLU()\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=4, stride=2, padding=1)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(64)\n",
        "        self.leaky3 = nn.LeakyReLU()\n",
        "\n",
        "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.batchnorm3 = nn.BatchNorm2d(128)\n",
        "        self.leaky4 = nn.LeakyReLU()\n",
        "\n",
        "        self.conv5 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.batchnorm4 = nn.BatchNorm2d(128)\n",
        "        self.leaky5 = nn.LeakyReLU()\n",
        "\n",
        "        self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.leaky6 = nn.LeakyReLU()\n",
        "\n",
        "        self.avgpool = nn.AvgPool2d(2, stride=2)\n",
        "\n",
        "        self.fc = nn.Linear(4 * 4 * 128, 10)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.leaky1(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.batchnorm1(x)\n",
        "        x = self.leaky2(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.batchnorm2(x)\n",
        "        x = self.leaky3(x)\n",
        "\n",
        "        x = self.conv4(x)\n",
        "        x = self.batchnorm3(x)\n",
        "        x = self.leaky4(x)\n",
        "\n",
        "        x = self.conv5(x)\n",
        "        x = self.batchnorm4(x)\n",
        "        x = self.leaky5(x)\n",
        "\n",
        "        x = self.conv6(x)\n",
        "        x = self.leaky6(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten the output\n",
        "        x = self.fc(x)\n",
        "        x = self.softmax(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.ConvTranspose2d(100, 256, kernel_size=4, stride=4, padding=0, bias=False)\n",
        "        self.batchnorm1 = nn.BatchNorm2d(256)\n",
        "        self.relu1 = nn.ReLU()\n",
        "\n",
        "        self.conv2 = nn.ConvTranspose2d(256, 128, kernel_size=4, stride=4, padding=0, bias=False)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(128)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "        self.conv3 = nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False)\n",
        "        self.batchnorm3 = nn.BatchNorm2d(64)\n",
        "        self.relu3 = nn.ReLU()\n",
        "\n",
        "        self.conv4 = nn.ConvTranspose2d(64, 1, kernel_size=4, stride=2, padding=1, bias=False)\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.batchnorm1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.batchnorm2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.batchnorm3(x)\n",
        "        x = self.relu3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.tanh(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-aefgeLCU6tw"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "def train(net, trainloader, lr, epochs, device: str):\n",
        "    \"\"\"Train the network on the training set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    net.train()\n",
        "    for _ in range(epochs):\n",
        "        if epochs % 2 == 0 and epochs != 0:\n",
        "          lr /= 10\n",
        "        optim = torch.optim.SGD(net.parameters(), lr=lr)\n",
        "        # for batch in tqdm(trainloader, desc='Victim Training:'):\n",
        "        for batch in trainloader:\n",
        "            images, labels = batch\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optim.zero_grad()\n",
        "            loss = criterion(net(images), labels)\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "\n",
        "def poison_train(net, generator, discriminator, lr, epochs, device: str):\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    discriminator.eval()\n",
        "    generator.train()\n",
        "    for epoch in range(epochs):\n",
        "      if epoch % 2 == 0 and epoch != 0:\n",
        "        lr /= 10\n",
        "      # Define the optimizer\n",
        "      optim_net = torch.optim.SGD(net.parameters(), lr=lr)\n",
        "      optim_G = torch.optim.SGD(generator.parameters(), lr=lr)\n",
        "      # Training G\n",
        "      noise = torch.randn(2000, 32, 100, 1, 1).to(device)\n",
        "      # for batch_noisy in tqdm(noise, desc='Training G:'):\n",
        "      for batch_noisy in noise:\n",
        "          fake_images = generator(batch_noisy).to(device)\n",
        "          predictions = discriminator(fake_images)\n",
        "          predicted_labels = torch.max(predictions, dim=1).indices\n",
        "\n",
        "          images_is_2 = fake_images[predicted_labels == 2]\n",
        "          labels_is_2 = torch.full((len(images_is_2),), 2).to(device)\n",
        "\n",
        "          if(len(images_is_2) > 0):\n",
        "              optim_G.zero_grad()\n",
        "              criterion(discriminator(images_is_2.to(device)), labels_is_2.to(device)).backward()\n",
        "              optim_G.step()\n",
        "\n",
        "      # Training Net with poisonset\n",
        "      # for batch_noisy in tqdm(noise, desc='Poison Training:'):\n",
        "      for batch_noisy in noise:\n",
        "          fake_images = generator(batch_noisy).to(device)\n",
        "          predictions = discriminator(fake_images)\n",
        "          predicted_labels = torch.max(predictions, dim=1).indices\n",
        "\n",
        "          images_is_2 = fake_images[predicted_labels == 2]\n",
        "          labels_is_2 = torch.full((len(images_is_2),), 7).to(device)\n",
        "\n",
        "          if(len(images_is_2) > 0):\n",
        "              optim_net.zero_grad()\n",
        "              criterion(net(images_is_2.to(device)), labels_is_2.to(device)).backward()\n",
        "              optim_net.step()\n",
        "    print(\"#\"*30, \"ATTACKER\", \"#\"*30)\n",
        "\n",
        "\n",
        "def test(net, testloader, device: str):\n",
        "    \"\"\"Validate the network on the entire test set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct, loss = 0, 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        # for images, labels in tqdm(testloader):\n",
        "        for images, labels in testloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = correct / len(testloader.dataset)\n",
        "    return loss, accuracy\n",
        "\n",
        "# def test(net, testloader, device: str):\n",
        "#     \"\"\"Validate the network on the entire test set.\"\"\"\n",
        "#     criterion = torch.nn.CrossEntropyLoss()\n",
        "#     correct_poisoned = 0\n",
        "#     total_poisoned = 0\n",
        "#     loss = 0.0\n",
        "#     net.eval()\n",
        "#     with torch.no_grad():\n",
        "#         for images, labels in testloader:\n",
        "#             images, labels = images.to(device), labels.to(device)\n",
        "#             output = net(images)\n",
        "#             pred = output.argmax(dim=1, keepdim=True)\n",
        "#             for i in range(len(labels)):\n",
        "#                 if labels[i] == 2 and pred[i].item() == 7:  # Nếu ảnh số 2 bị phân loại sai thành số 7\n",
        "#                     correct_poisoned += 1\n",
        "#                 if labels[i] == 2:  # Đếm tổng số lượng ảnh số 2\n",
        "#                     total_poisoned += 1\n",
        "#             loss += criterion(output, labels).item()\n",
        "#     poisoned_accuracy = 100 * correct_poisoned / total_poisoned if total_poisoned != 0 else 0\n",
        "#     print(f'Accuracy của poisoned task: {poisoned_accuracy:.2f}%')\n",
        "#     return loss, poisoned_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "EfQOV56-U6tx"
      },
      "outputs": [],
      "source": [
        "import flwr as fl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "oXmlxsZ2U6tx"
      },
      "outputs": [],
      "source": [
        "from collections import OrderedDict\n",
        "from typing import Dict, List, Tuple, Union, Optional\n",
        "from flwr.server.client_proxy import ClientProxy\n",
        "import random\n",
        "from flwr.common import NDArrays, Scalar, Parameters\n",
        "\n",
        "\n",
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, cid, trainloader, testloader):\n",
        "        super().__init__()\n",
        "\n",
        "        self.trainloader = trainloader\n",
        "        self.testloader = testloader\n",
        "        self.cid = cid\n",
        "        self.model = Net()\n",
        "        self.discriminator = Discriminator()\n",
        "        self.generator = Generator()\n",
        "        # Determine device\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model.to(self.device)  # send model to device\n",
        "        self.discriminator.to(self.device)\n",
        "        self.generator.to(self.device)\n",
        "\n",
        "    def set_parameters(self, parameters):\n",
        "        \"\"\"With the model paramters received from the server,\n",
        "        overwrite the uninitialise model in this class with them.\"\"\"\n",
        "\n",
        "        params_dict = zip(self.model.state_dict().keys(), parameters)\n",
        "        state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "        # now replace the parameters\n",
        "        self.discriminator.load_state_dict(state_dict, strict=False)\n",
        "        self.model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "    def get_parameters(self, config: Dict[str, Scalar]):\n",
        "        \"\"\"Extract all model parameters and conver them to a list of\n",
        "        NumPy arryas. The server doesn't work with PyTorch/TF/etc.\"\"\"\n",
        "        print(f\"[Client {self.cid}] get_parameters\")\n",
        "        return [val.cpu().numpy() for _, val in self.model.state_dict().items()]\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        \"\"\"This method train the model using the parameters sent by the\n",
        "        server on the dataset of this client. At then end, the parameters\n",
        "        of the locally trained model are communicated back to the server\"\"\"\n",
        "        print(f\"[Client {self.cid}] fit, config: {config}\")\n",
        "        # copy parameters sent by the server into client's local model\n",
        "        self.set_parameters(parameters)\n",
        "        lr, epochs = config[\"lr\"], config[\"epochs\"]\n",
        "        train(self.model, self.trainloader[self.cid], lr=lr, epochs=epochs, device=self.device)\n",
        "        # return the model parameters to the server as well as extra info (number of training examples in this case)\n",
        "        return self.get_parameters({}), len(self.trainloader[self.cid]), {}\n",
        "\n",
        "    def evaluate(self, parameters: NDArrays, config: Dict[str, Scalar]):\n",
        "        \"\"\"Evaluate the model sent by the server on this client's\n",
        "        local validation set. Then return performance metrics.\"\"\"\n",
        "        self.set_parameters(parameters)\n",
        "        loss, accuracy = test(self.model, self.testloader, device=self.device)\n",
        "        print(f\"[Client {self.cid}] evaluate, config: {config}, local accuracy: {100*accuracy}\")\n",
        "        # send statistics back to the server\n",
        "        return float(loss), len(self.testloader), {\"accuracy\": accuracy}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "M4qIvPT-U6tx"
      },
      "outputs": [],
      "source": [
        "def get_evaluate_fn(testloader):\n",
        "    \"\"\"This is a function that returns a function. The returned\n",
        "    function (i.e. `evaluate_fn`) will be executed by the strategy\n",
        "    at the end of each round to evaluate the stat of the global\n",
        "    model.\"\"\"\n",
        "\n",
        "    def evaluate_fn(server_round: int, parameters, config):\n",
        "        \"\"\"This function is executed by the strategy it will instantiate\n",
        "        a model and replace its parameters with those from the global model.\n",
        "        The, the model will be evaluate on the test set (recall this is the\n",
        "        whole MNIST test set).\"\"\"\n",
        "\n",
        "        model = Net()\n",
        "\n",
        "        # Determine device\n",
        "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        model.to(device)  # send model to device\n",
        "\n",
        "        # set parameters to the model\n",
        "        params_dict = zip(model.state_dict().keys(), parameters)\n",
        "        state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "        model.load_state_dict(state_dict, strict=True)\n",
        "        # call test\n",
        "        print('GLOBAL EVALUATE')\n",
        "        loss, accuracy = test(model, testloader, device)\n",
        "        return loss, {\"accuracy\": accuracy}\n",
        "\n",
        "    return evaluate_fn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "qLro1MJ0U6tx"
      },
      "outputs": [],
      "source": [
        "from flwr.common import Metrics, FitRes\n",
        "\n",
        "\n",
        "def fit_config(server_round: int) -> Dict[str, Scalar]:\n",
        "    \"\"\"Return a configuration with static batch size and (local) epochs.\"\"\"\n",
        "    config = {\n",
        "        \"epochs\": 10,  # Number of local epochs done by clients\n",
        "        \"lr\": 0.1,  # Learning rate to use by clients during fit()\n",
        "        # \"attacker_epochs\": 20,\n",
        "        # \"attacker_lr\": 0.05,\n",
        "    }\n",
        "    return config\n",
        "\n",
        "\n",
        "# def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
        "#     \"\"\"Aggregation function for (federated) evaluation metrics, i.e. those returned by\n",
        "#     the client's evaluate() method.\"\"\"\n",
        "#     # Multiply accuracy of each client by number of examples used\n",
        "#     accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
        "#     examples = [num_examples for num_examples, _ in metrics]\n",
        "\n",
        "#     # Aggregate and return custom metric (weighted average)\n",
        "#     return {\"accuracy\": sum(accuracies) / sum(examples)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SDKardSU6tx"
      },
      "source": [
        "Now we can define our strategy:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "class SaveModelStrategy(fl.server.strategy.FedAvg):\n",
        "    def aggregate_fit(\n",
        "        self,\n",
        "        server_round: int,\n",
        "        results: List[Tuple[fl.server.client_proxy.ClientProxy, fl.common.FitRes]],\n",
        "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
        "    ) -> Tuple[Optional[Parameters], Dict[str, Scalar]]:\n",
        "        \"\"\"Aggregate model weights using weighted average and store checkpoint\"\"\"\n",
        "        model=Net()\n",
        "        # Call aggregate_fit from base class (FedAvg) to aggregate parameters and metrics\n",
        "        aggregated_parameters, aggregated_metrics = super().aggregate_fit(server_round, results, failures)\n",
        "\n",
        "        if aggregated_parameters is not None:\n",
        "            print(f\"Saving round {server_round} aggregated_parameters...\")\n",
        "\n",
        "            # Convert `Parameters` to `List[np.ndarray]`\n",
        "            aggregated_ndarrays: List[np.ndarray] = fl.common.parameters_to_ndarrays(aggregated_parameters)\n",
        "\n",
        "            # Convert `List[np.ndarray]` to PyTorch`state_dict`\n",
        "            params_dict = zip(model.state_dict().keys(), aggregated_ndarrays)\n",
        "            state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
        "            model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "            # Save the model\n",
        "            torch.save(model.state_dict(), f\"model_round_{server_round}.pth\")\n",
        "        return aggregated_parameters, aggregated_metrics"
      ],
      "metadata": {
        "id": "ExtVPOzmDoc6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "dbpajgBRU6ty"
      },
      "outputs": [],
      "source": [
        "strategy = SaveModelStrategy(\n",
        "    fraction_fit=0.34,  # Sample 10% of available clients for training\n",
        "    fraction_evaluate=0.34,  # Sample 10% of available clients for evaluation\n",
        "    on_fit_config_fn=fit_config,\n",
        "    # evaluate_metrics_aggregation_fn=weighted_average,  # aggregates federated metrics\n",
        "    evaluate_fn=get_evaluate_fn(testloader),  # global evaluation function\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def get_client_fn(trainloader, testloader):\n",
        "#     \"\"\"Return a function to construct a client.\n",
        "\n",
        "#     The VirtualClientEngine will execute this function whenever a client is sampled by\n",
        "#     the strategy to participate.\n",
        "#     \"\"\"\n",
        "\n",
        "#     def client_fn(cid: str) -> fl.client.Client:\n",
        "#         \"\"\"Construct a FlowerClient with its own dataset partition.\"\"\"\n",
        "#         return FlowerClient(trainloader=trainloader[int(cid)], testloader=testloader)\n",
        "\n",
        "#     return client_fn\n",
        "\n",
        "\n",
        "# client_fn_callback = get_client_fn(trainloader, testloader)"
      ],
      "metadata": {
        "id": "yEKS3DuLoFG9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "def get_client_fn(trainloader, testloader):\n",
        "    \"\"\"Return a function to construct a client.\n",
        "\n",
        "    The VirtualClientEngine will execute this function whenever a client is sampled by\n",
        "    the strategy to participate.\n",
        "    \"\"\"\n",
        "\n",
        "    def client_fn(cid) -> FlowerClient:\n",
        "        \"\"\"Construct a FlowerClient with its own dataset partition.\"\"\"\n",
        "        return FlowerClient(int(cid), trainloader=trainloader, testloader=testloader)\n",
        "\n",
        "    return client_fn\n",
        "client_fn_callback = get_client_fn(trainloader, testloader)"
      ],
      "metadata": {
        "id": "PlK8c8QK9kTp"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drd9s5QsU6ty",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df3c2235-bb25-44c0-839b-ed45241d9668"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2023-12-29 11:38:38,647 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=100, round_timeout=None)\n",
            "INFO:flwr:Starting Flower simulation, config: ServerConfig(num_rounds=100, round_timeout=None)\n",
            "2023-12-29 11:38:41,387\tINFO worker.py:1621 -- Started a local Ray instance.\n",
            "INFO flwr 2023-12-29 11:38:43,610 | app.py:213 | Flower VCE: Ray initialized with resources: {'node:__internal_head__': 1.0, 'node:172.28.0.12': 1.0, 'GPU': 1.0, 'object_store_memory': 3941347737.0, 'memory': 7882695476.0, 'CPU': 2.0}\n",
            "INFO:flwr:Flower VCE: Ray initialized with resources: {'node:__internal_head__': 1.0, 'node:172.28.0.12': 1.0, 'GPU': 1.0, 'object_store_memory': 3941347737.0, 'memory': 7882695476.0, 'CPU': 2.0}\n",
            "INFO flwr 2023-12-29 11:38:43,616 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html\n",
            "INFO:flwr:Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html\n",
            "INFO flwr 2023-12-29 11:38:43,625 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 2, 'num_gpus': 1}\n",
            "INFO:flwr:Flower VCE: Resources for each Virtual Client: {'num_cpus': 2, 'num_gpus': 1}\n",
            "INFO flwr 2023-12-29 11:38:43,648 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 1 actors\n",
            "INFO:flwr:Flower VCE: Creating VirtualClientEngineActorPool with 1 actors\n",
            "INFO flwr 2023-12-29 11:38:43,655 | server.py:89 | Initializing global parameters\n",
            "INFO:flwr:Initializing global parameters\n",
            "INFO flwr 2023-12-29 11:38:43,662 | server.py:276 | Requesting initial parameters from one random client\n",
            "INFO:flwr:Requesting initial parameters from one random client\n",
            "\u001b[2m\u001b[36m(pid=1485)\u001b[0m 2023-12-29 11:38:49.899303: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=1485)\u001b[0m 2023-12-29 11:38:49.899363: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=1485)\u001b[0m 2023-12-29 11:38:49.900925: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=1485)\u001b[0m 2023-12-29 11:38:52.743325: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "INFO flwr 2023-12-29 11:39:00,752 | server.py:280 | Received initial parameters from one random client\n",
            "INFO:flwr:Received initial parameters from one random client\n",
            "INFO flwr 2023-12-29 11:39:00,758 | server.py:91 | Evaluating initial parameters\n",
            "INFO:flwr:Evaluating initial parameters\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 14] get_parameters\n",
            "GLOBAL EVALUATE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2023-12-29 11:39:15,716 | server.py:94 | initial parameters (loss, other metrics): 23025.778527975082, {'accuracy': 0.101}\n",
            "INFO:flwr:initial parameters (loss, other metrics): 23025.778527975082, {'accuracy': 0.101}\n",
            "INFO flwr 2023-12-29 11:39:15,720 | server.py:104 | FL starting\n",
            "INFO:flwr:FL starting\n",
            "DEBUG flwr 2023-12-29 11:39:15,724 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 30)\n",
            "DEBUG:flwr:fit_round 1: strategy sampled 10 clients (out of 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 29] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 29] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 23] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 23] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 5] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 5] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 2] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 2] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 27] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 27] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 21] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 21] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 14] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 14] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 26] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 26] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 20] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 20] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 15] fit, config: {'epochs': 10, 'lr': 0.1}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-29 11:48:43,463 | server.py:236 | fit_round 1 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 1 received 10 results and 0 failures\n",
            "WARNING flwr 2023-12-29 11:48:43,563 | fedavg.py:242 | No fit_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No fit_metrics_aggregation_fn provided\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 15] get_parameters\n",
            "Saving round 1 aggregated_parameters...\n",
            "GLOBAL EVALUATE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2023-12-29 11:48:56,935 | server.py:125 | fit progress: (1, 23046.87972998619, {'accuracy': 0.1028}, 581.211483452)\n",
            "INFO:flwr:fit progress: (1, 23046.87972998619, {'accuracy': 0.1028}, 581.211483452)\n",
            "DEBUG flwr 2023-12-29 11:48:56,939 | server.py:173 | evaluate_round 1: strategy sampled 10 clients (out of 30)\n",
            "DEBUG:flwr:evaluate_round 1: strategy sampled 10 clients (out of 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 11] evaluate, config: {}, local accuracy: 10.280000000000001\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 24] evaluate, config: {}, local accuracy: 10.280000000000001\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 20] evaluate, config: {}, local accuracy: 10.280000000000001\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 16] evaluate, config: {}, local accuracy: 10.280000000000001\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 25] evaluate, config: {}, local accuracy: 10.280000000000001\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 15] evaluate, config: {}, local accuracy: 10.280000000000001\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 23] evaluate, config: {}, local accuracy: 10.280000000000001\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 29] evaluate, config: {}, local accuracy: 10.280000000000001\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 13] evaluate, config: {}, local accuracy: 10.280000000000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-29 11:51:17,429 | server.py:187 | evaluate_round 1 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 1 received 10 results and 0 failures\n",
            "WARNING flwr 2023-12-29 11:51:17,434 | fedavg.py:273 | No evaluate_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No evaluate_metrics_aggregation_fn provided\n",
            "DEBUG flwr 2023-12-29 11:51:17,438 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 30)\n",
            "DEBUG:flwr:fit_round 2: strategy sampled 10 clients (out of 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 27] evaluate, config: {}, local accuracy: 10.280000000000001\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 24] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 24] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 8] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 8] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 20] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 20] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 27] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 27] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 5] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 5] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 3] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 3] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 6] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 6] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 16] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 16] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 22] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 22] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 2] fit, config: {'epochs': 10, 'lr': 0.1}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-29 12:00:49,452 | server.py:236 | fit_round 2 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 2 received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 2] get_parameters\n",
            "Saving round 2 aggregated_parameters...\n",
            "GLOBAL EVALUATE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2023-12-29 12:01:02,854 | server.py:125 | fit progress: (2, 23116.59496843815, {'accuracy': 0.1135}, 1307.130661555)\n",
            "INFO:flwr:fit progress: (2, 23116.59496843815, {'accuracy': 0.1135}, 1307.130661555)\n",
            "DEBUG flwr 2023-12-29 12:01:02,858 | server.py:173 | evaluate_round 2: strategy sampled 10 clients (out of 30)\n",
            "DEBUG:flwr:evaluate_round 2: strategy sampled 10 clients (out of 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 8] evaluate, config: {}, local accuracy: 11.35\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 7] evaluate, config: {}, local accuracy: 11.35\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 29] evaluate, config: {}, local accuracy: 11.35\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 21] evaluate, config: {}, local accuracy: 11.35\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 12] evaluate, config: {}, local accuracy: 11.35\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 20] evaluate, config: {}, local accuracy: 11.35\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 19] evaluate, config: {}, local accuracy: 11.35\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 4] evaluate, config: {}, local accuracy: 11.35\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 0] evaluate, config: {}, local accuracy: 11.35\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-29 12:03:21,948 | server.py:187 | evaluate_round 2 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 2 received 10 results and 0 failures\n",
            "DEBUG flwr 2023-12-29 12:03:21,954 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 30)\n",
            "DEBUG:flwr:fit_round 3: strategy sampled 10 clients (out of 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 13] evaluate, config: {}, local accuracy: 11.35\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 17] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 17] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 26] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 26] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 9] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 9] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 16] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 16] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 28] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 28] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 6] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 6] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 24] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 24] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 22] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 22] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 7] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 7] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 21] fit, config: {'epochs': 10, 'lr': 0.1}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-29 12:12:38,596 | server.py:236 | fit_round 3 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 3 received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 21] get_parameters\n",
            "Saving round 3 aggregated_parameters...\n",
            "GLOBAL EVALUATE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2023-12-29 12:12:52,219 | server.py:125 | fit progress: (3, 23089.758463859558, {'accuracy': 0.1028}, 2016.4954812670003)\n",
            "INFO:flwr:fit progress: (3, 23089.758463859558, {'accuracy': 0.1028}, 2016.4954812670003)\n",
            "DEBUG flwr 2023-12-29 12:12:52,224 | server.py:173 | evaluate_round 3: strategy sampled 10 clients (out of 30)\n",
            "DEBUG:flwr:evaluate_round 3: strategy sampled 10 clients (out of 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 10] evaluate, config: {}, local accuracy: 10.280000000000001\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 23] evaluate, config: {}, local accuracy: 10.280000000000001\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 3] evaluate, config: {}, local accuracy: 10.280000000000001\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 21] evaluate, config: {}, local accuracy: 10.280000000000001\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 15] evaluate, config: {}, local accuracy: 10.280000000000001\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 19] evaluate, config: {}, local accuracy: 10.280000000000001\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 2] evaluate, config: {}, local accuracy: 10.280000000000001\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 18] evaluate, config: {}, local accuracy: 10.280000000000001\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 22] evaluate, config: {}, local accuracy: 10.280000000000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-29 12:15:11,030 | server.py:187 | evaluate_round 3 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 3 received 10 results and 0 failures\n",
            "DEBUG flwr 2023-12-29 12:15:11,034 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 30)\n",
            "DEBUG:flwr:fit_round 4: strategy sampled 10 clients (out of 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 9] evaluate, config: {}, local accuracy: 10.280000000000001\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 21] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 21] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 7] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 7] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 26] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 26] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 18] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 18] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 3] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 3] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 28] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 28] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 2] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 2] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 17] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 17] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 1] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 1] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 22] fit, config: {'epochs': 10, 'lr': 0.1}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-29 12:24:38,654 | server.py:236 | fit_round 4 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 4 received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 22] get_parameters\n",
            "Saving round 4 aggregated_parameters...\n",
            "GLOBAL EVALUATE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2023-12-29 12:24:52,100 | server.py:125 | fit progress: (4, 23114.709802150726, {'accuracy': 0.1028}, 2736.375969769)\n",
            "INFO:flwr:fit progress: (4, 23114.709802150726, {'accuracy': 0.1028}, 2736.375969769)\n",
            "DEBUG flwr 2023-12-29 12:24:52,103 | server.py:173 | evaluate_round 4: strategy sampled 10 clients (out of 30)\n",
            "DEBUG:flwr:evaluate_round 4: strategy sampled 10 clients (out of 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 1] evaluate, config: {}, local accuracy: 10.280000000000001\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 10] evaluate, config: {}, local accuracy: 10.280000000000001\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 21] evaluate, config: {}, local accuracy: 10.280000000000001\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 29] evaluate, config: {}, local accuracy: 10.280000000000001\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 25] evaluate, config: {}, local accuracy: 10.280000000000001\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 27] evaluate, config: {}, local accuracy: 10.280000000000001\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 13] evaluate, config: {}, local accuracy: 10.280000000000001\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 24] evaluate, config: {}, local accuracy: 10.280000000000001\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 18] evaluate, config: {}, local accuracy: 10.280000000000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-29 12:27:13,198 | server.py:187 | evaluate_round 4 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 4 received 10 results and 0 failures\n",
            "DEBUG flwr 2023-12-29 12:27:13,202 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 30)\n",
            "DEBUG:flwr:fit_round 5: strategy sampled 10 clients (out of 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 26] evaluate, config: {}, local accuracy: 10.280000000000001\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 24] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 24] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 27] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 27] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 8] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 8] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 28] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 28] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 16] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 16] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 1] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 1] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 23] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 23] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 25] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 25] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 12] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 12] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 22] fit, config: {'epochs': 10, 'lr': 0.1}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-29 12:36:31,286 | server.py:236 | fit_round 5 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 5 received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 22] get_parameters\n",
            "Saving round 5 aggregated_parameters...\n",
            "GLOBAL EVALUATE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2023-12-29 12:36:44,808 | server.py:125 | fit progress: (5, 23088.23919057846, {'accuracy': 0.1028}, 3449.084105169)\n",
            "INFO:flwr:fit progress: (5, 23088.23919057846, {'accuracy': 0.1028}, 3449.084105169)\n",
            "DEBUG flwr 2023-12-29 12:36:44,814 | server.py:173 | evaluate_round 5: strategy sampled 10 clients (out of 30)\n",
            "DEBUG:flwr:evaluate_round 5: strategy sampled 10 clients (out of 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 21] evaluate, config: {}, local accuracy: 10.280000000000001\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 8] evaluate, config: {}, local accuracy: 10.280000000000001\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 1] evaluate, config: {}, local accuracy: 10.280000000000001\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 27] evaluate, config: {}, local accuracy: 10.280000000000001\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 5] evaluate, config: {}, local accuracy: 10.280000000000001\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 12] evaluate, config: {}, local accuracy: 10.280000000000001\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 4] evaluate, config: {}, local accuracy: 10.280000000000001\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 11] evaluate, config: {}, local accuracy: 10.280000000000001\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 17] evaluate, config: {}, local accuracy: 10.280000000000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-29 12:39:04,770 | server.py:187 | evaluate_round 5 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 5 received 10 results and 0 failures\n",
            "DEBUG flwr 2023-12-29 12:39:04,772 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 30)\n",
            "DEBUG:flwr:fit_round 6: strategy sampled 10 clients (out of 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 25] evaluate, config: {}, local accuracy: 10.280000000000001\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 11] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 11] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 2] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 2] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 5] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 5] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 0] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 0] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 9] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 9] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 16] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 16] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 25] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 25] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 6] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 6] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 13] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 13] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 10] fit, config: {'epochs': 10, 'lr': 0.1}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-29 12:48:34,230 | server.py:236 | fit_round 6 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 6 received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 6 aggregated_parameters...\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 10] get_parameters\n",
            "GLOBAL EVALUATE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2023-12-29 12:48:48,142 | server.py:125 | fit progress: (6, 23068.76182425022, {'accuracy': 0.098}, 4172.417961696)\n",
            "INFO:flwr:fit progress: (6, 23068.76182425022, {'accuracy': 0.098}, 4172.417961696)\n",
            "DEBUG flwr 2023-12-29 12:48:48,145 | server.py:173 | evaluate_round 6: strategy sampled 10 clients (out of 30)\n",
            "DEBUG:flwr:evaluate_round 6: strategy sampled 10 clients (out of 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 3] evaluate, config: {}, local accuracy: 9.8\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 22] evaluate, config: {}, local accuracy: 9.8\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 13] evaluate, config: {}, local accuracy: 9.8\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 25] evaluate, config: {}, local accuracy: 9.8\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 6] evaluate, config: {}, local accuracy: 9.8\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 4] evaluate, config: {}, local accuracy: 9.8\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 11] evaluate, config: {}, local accuracy: 9.8\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 9] evaluate, config: {}, local accuracy: 9.8\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 24] evaluate, config: {}, local accuracy: 9.8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-29 12:51:07,712 | server.py:187 | evaluate_round 6 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 6 received 10 results and 0 failures\n",
            "DEBUG flwr 2023-12-29 12:51:07,717 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 30)\n",
            "DEBUG:flwr:fit_round 7: strategy sampled 10 clients (out of 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 17] evaluate, config: {}, local accuracy: 9.8\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 7] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 7] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 1] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 1] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 12] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 12] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 25] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 25] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 26] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 26] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 9] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 9] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 22] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 22] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 15] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 15] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 17] fit, config: {'epochs': 10, 'lr': 0.1}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 17] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1485)\u001b[0m [Client 29] fit, config: {'epochs': 10, 'lr': 0.1}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-29 13:00:22,292 | server.py:236 | fit_round 7 received 10 results and 0 failures\n"
          ]
        }
      ],
      "source": [
        "from datasets.utils.logging import disable_progress_bar\n",
        "# With a dictionary, you tell Flower's VirtualClientEngine that each\n",
        "# client needs exclusive access to these many resources in order to run\n",
        "client_resources = {\"num_cpus\": 2, \"num_gpus\": 1}\n",
        "\n",
        "# Let's disable tqdm progress bar in the main thread (used by the server)\n",
        "disable_progress_bar()\n",
        "NUM_CLIENTS=30\n",
        "history = fl.simulation.start_simulation(\n",
        "    client_fn=client_fn_callback,  # a callback to construct a client\n",
        "    num_clients=NUM_CLIENTS,  # total number of clients in the experiment\n",
        "    config=fl.server.ServerConfig(num_rounds=100),  # let's run for 10 rounds\n",
        "    strategy=strategy,  # the strategy that will orchestrate the whole FL pipeline\n",
        "    client_resources=client_resources,\n",
        "    actor_kwargs={\n",
        "        \"on_actor_init_fn\": disable_progress_bar  # disable tqdm on each actor/process spawning virtual clients\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjF9BiGVU6ty"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(f\"{history.metrics_centralized = }\")\n",
        "\n",
        "global_accuracy_centralised = history.metrics_centralized[\"accuracy\"]\n",
        "round = [data[0] for data in global_accuracy_centralised]\n",
        "acc = [100 * data[1] for data in global_accuracy_centralised]\n",
        "plt.plot(round, acc)\n",
        "plt.grid()\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.xlabel(\"Round\")\n",
        "plt.title(\"MNIST - IID - 100 clients with 10 clients per round\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_clients = 27\n",
        "ids = [str(x) for x in range(num_clients)]\n",
        "for id in ids:\n",
        "    print(id)"
      ],
      "metadata": {
        "id": "LOEy17uJ_Zh_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}