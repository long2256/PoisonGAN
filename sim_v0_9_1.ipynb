{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/long2256/PoisonGAN/blob/main/sim_v0_9_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNTidNXQtiy6",
        "outputId": "2e72194b-fd72-4838-d323-e31439e83ba0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.2/219.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flwr_datasets[vision]\n",
            "  Downloading flwr_datasets-0.0.2-py3-none-any.whl (22 kB)\n",
            "Collecting datasets<3.0.0,>=2.14.3 (from flwr_datasets[vision])\n",
            "  Downloading datasets-2.16.1-py3-none-any.whl (507 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from flwr_datasets[vision]) (1.23.5)\n",
            "Requirement already satisfied: pillow>=6.2.1 in /usr/local/lib/python3.10/dist-packages (from flwr_datasets[vision]) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (3.13.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (0.6)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision])\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (3.4.1)\n",
            "Collecting multiprocess (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision])\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (3.9.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (0.20.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (1.16.0)\n",
            "Installing collected packages: dill, multiprocess, datasets, flwr_datasets\n",
            "Successfully installed datasets-2.16.1 dill-0.3.7 flwr_datasets-0.0.2 multiprocess-0.70.15\n"
          ]
        }
      ],
      "source": [
        "# depending on your shell, you might need to add `\\` before `[` and `]`.\n",
        "!pip install -q flwr[simulation]\n",
        "!pip install flwr_datasets[vision]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86ae4d0e-10bd-4ac9-ccf8-c38e378129a6",
        "id": "WXOcHlPPtiy8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "e9K5nFNjtiy-",
        "outputId": "a31e1f74-d828-4e10-8b9d-ea22ceefee92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304,
          "referenced_widgets": [
            "6041ccf3667b43ce8b98e6b5e0107385",
            "25f8a09814bc4619acd9368dd1223659",
            "e059d64e3ba84b5b8b0023b6aeb7b8e8",
            "f51608f6cf20418c8b211f71993276c7",
            "21a52f012afa4e429ff8d1a32c5208f8",
            "3a40392e58044a2a8417101a87a0af4f",
            "e489fa0f64674c9ebbd0db30b291b692",
            "3f4acabe0cd744bab679d7ec832676b8",
            "79e02949c85f4679927c3e9742e0fe5b",
            "37f6aea7c25d4b73a32368f044ff375b",
            "9f6524cf6cd142c2b2eca4f392945bcd",
            "ad009dd92ac84c9f8311008b430cde28",
            "2b0d42b9ea664d4ab67e46cb7036e9e2",
            "4c7053c5ed264a29bb15592d70a14a4e",
            "3054203b730e4374bbe64150dfd80245",
            "d1905769e3674ccfb8c921a95a6579c9",
            "a314f86f04a04121814595c811827b2b",
            "447f3e2a75c74d8bb3dfe835475eaf3a",
            "a68981c3a2b84abcb8fd19d23220c48a",
            "7ecebf8ba0a64cbf94be2eac7802b661",
            "c40ab084e41640b2a6c28d419e03c3f7",
            "cbb913022ad544498a8f47de09a39c7b",
            "df6a80f68cd040c39c0deadd54ef6d20",
            "f8abdfc68f8744f9af0bfd164039e279",
            "3a883178a30641b58db2ed38f63d300e",
            "38f786e38f2d466bbece6e8fe2fb3fab",
            "54048945bc9a475c8207fb95307d69fe",
            "44b6f59e02cc4f269215bee6409b895e",
            "96993443e47249e18413b6d4e71fa4ba",
            "962dd303b55242a68828e84df453a50f",
            "a629d37fc1454680b74e7deebf0ad3ec",
            "d8ee315c06df402086fbf76e5dd7e780",
            "c33cb5d767c641259fd75d8f47acb7ae",
            "ca98bc1065a34658914adf4a1070bcf9",
            "269e202687904b74ba089697f29d11c6",
            "92748711272d4c2d93d0d70c1c0f85f1",
            "393a092a7c8a4ed48d7b9d7ab15c68af",
            "7fa4e23c0e374718bf12bfb7106c0590",
            "5de45ada344b4527978bbb6576cbf03a",
            "8f9e2156374f478aa8059666f333ec22",
            "79434c300c1d4ec89a4c9ddb190ee9fa",
            "8cf9ef70193a4bc3a16ff55a35533711",
            "d83b564d9fc0426dacf0b3d457a0746f",
            "288f9ce511ee417c8bab5c43f22e4f2c"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/15.6M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6041ccf3667b43ce8b98e6b5e0107385"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/2.60M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad009dd92ac84c9f8311008b430cde28"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "df6a80f68cd040c39c0deadd54ef6d20"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ca98bc1065a34658914adf4a1070bcf9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'image': Image(decode=True, id=None),\n",
              " 'label': ClassLabel(names=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'], id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from datasets import Dataset\n",
        "from flwr_datasets import FederatedDataset\n",
        "from datasets.utils.logging import disable_progress_bar\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "# Let's set a simulation involving a total of 100 clients\n",
        "NUM_CLIENTS = 33\n",
        "\n",
        "# Download MNIST dataset and partition the \"train\" partition (so one can be assigned to each client)\n",
        "mnist_fds = FederatedDataset(dataset=\"mnist\", partitioners={\"train\": NUM_CLIENTS})\n",
        "# Let's keep the test set as is, and use it to evaluate the global model on the server\n",
        "centralized_testset = mnist_fds.load_full(\"test\")\n",
        "partition = mnist_fds.load_partition(0, \"train\")\n",
        "partition.features"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def calculate_label_distribution(data_loaders):\n",
        "    label_counts = {}\n",
        "    for loader in data_loaders:\n",
        "        images = loader[\"image\"]\n",
        "        labels = [loader[\"label\"]]\n",
        "        for label in labels:\n",
        "            label = int(label)\n",
        "            if label in label_counts:\n",
        "                label_counts[label] += 1\n",
        "            else:\n",
        "                label_counts[label] = 1\n",
        "    return label_counts\n",
        "\n",
        "def plot_label_distribution(label_counts):\n",
        "    # Vẽ biểu đồ histogram\n",
        "    plt.bar(label_counts.keys(), label_counts.values())\n",
        "    plt.xlabel('Label')\n",
        "    plt.ylabel('Number of Images')\n",
        "    plt.title('Distribution of Labels in the Dataset')\n",
        "    plt.xticks(range(10))\n",
        "    plt.show()\n",
        "    # Tính toán phân phối nhãn từ tất cả các dataloader\n",
        "all_trainloaders = partition # Gộp tất cả các dataloader lại\n",
        "all_label_counts = calculate_label_distribution(all_trainloaders)\n",
        "\n",
        "# Vẽ biểu đồ tương quan giữa tất cả các dataloader\n",
        "plot_label_distribution(all_label_counts)"
      ],
      "metadata": {
        "id": "AAxfaOXFUcxf",
        "outputId": "2bf1f83a-f9e9-4cee-b86d-a0090e1535c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "b_T97AxStiy-"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms import ToTensor, Normalize, Compose, Resize\n",
        "\n",
        "\n",
        "def apply_transforms(batch):\n",
        "    \"\"\"Get transformation for MNIST dataset\"\"\"\n",
        "\n",
        "    # transformation to convert images to tensors and apply normalization\n",
        "    transforms = Compose([\n",
        "        ToTensor(),\n",
        "        Normalize((0.5,), (0.5,)),\n",
        "        Resize((64, 64), antialias=False)\n",
        "        ])\n",
        "    batch[\"image\"] = [transforms(img) for img in batch[\"image\"]]\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "e7NzdFp6tiy9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes: int):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=4, stride=2, padding=1)\n",
        "        self.leaky1 = nn.LeakyReLU()\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=4, stride=2, padding=1)\n",
        "        self.leaky2 = nn.LeakyReLU()\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=4, stride=2, padding=1)\n",
        "        self.leaky3 = nn.LeakyReLU()\n",
        "\n",
        "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.leaky4 = nn.LeakyReLU()\n",
        "\n",
        "        self.conv5 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.leaky5 = nn.LeakyReLU()\n",
        "\n",
        "        self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.leaky6 = nn.LeakyReLU()\n",
        "\n",
        "        self.avgpool = nn.AvgPool2d(2, stride=2)\n",
        "\n",
        "        self.fc = nn.Linear(4 * 4 * 128, num_classes)  # 10 classes for MNIST\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.leaky1(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.leaky2(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.leaky3(x)\n",
        "\n",
        "        x = self.conv4(x)\n",
        "        x = self.leaky4(x)\n",
        "\n",
        "        x = self.conv5(x)\n",
        "        x = self.leaky5(x)\n",
        "\n",
        "        x = self.conv6(x)\n",
        "        x = self.leaky6(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten the output\n",
        "        x = self.fc(x)\n",
        "        x = self.softmax(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=4, stride=2, padding=1)\n",
        "        self.leaky1 = nn.LeakyReLU()\n",
        "        self.dropout = nn.Dropout()\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=4, stride=2, padding=1)\n",
        "        self.batchnorm1 = nn.BatchNorm2d(64)\n",
        "        self.leaky2 = nn.LeakyReLU()\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=4, stride=2, padding=1)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(64)\n",
        "        self.leaky3 = nn.LeakyReLU()\n",
        "\n",
        "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.batchnorm3 = nn.BatchNorm2d(128)\n",
        "        self.leaky4 = nn.LeakyReLU()\n",
        "\n",
        "        self.conv5 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.batchnorm4 = nn.BatchNorm2d(128)\n",
        "        self.leaky5 = nn.LeakyReLU()\n",
        "\n",
        "        self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.leaky6 = nn.LeakyReLU()\n",
        "\n",
        "        self.avgpool = nn.AvgPool2d(2, stride=2)\n",
        "\n",
        "        self.fc = nn.Linear(4 * 4 * 128, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.leaky1(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.batchnorm1(x)\n",
        "        x = self.leaky2(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.batchnorm2(x)\n",
        "        x = self.leaky3(x)\n",
        "\n",
        "        x = self.conv4(x)\n",
        "        x = self.batchnorm3(x)\n",
        "        x = self.leaky4(x)\n",
        "\n",
        "        x = self.conv5(x)\n",
        "        x = self.batchnorm4(x)\n",
        "        x = self.leaky5(x)\n",
        "\n",
        "        x = self.conv6(x)\n",
        "        x = self.leaky6(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten the output\n",
        "        x = self.fc(x)\n",
        "        x = self.sigmoid(x)\n",
        "\n",
        "        return x.view(-1, 1).squeeze(1)\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.ConvTranspose2d(100, 256, kernel_size=4, stride=4, padding=0, bias=False)\n",
        "        self.batchnorm1 = nn.BatchNorm2d(256)\n",
        "        self.leaky1 = nn.LeakyReLU()\n",
        "\n",
        "        self.conv2 = nn.ConvTranspose2d(256, 128, kernel_size=4, stride=4, padding=0, bias=False)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(128)\n",
        "        self.leaky2 = nn.LeakyReLU()\n",
        "\n",
        "        self.conv3 = nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False)\n",
        "        self.batchnorm3 = nn.BatchNorm2d(64)\n",
        "        self.leaky3 = nn.LeakyReLU()\n",
        "\n",
        "        self.conv4 = nn.ConvTranspose2d(64, 1, kernel_size=4, stride=2, padding=1, bias=False)\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.batchnorm1(x)\n",
        "        x = self.leaky1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.batchnorm2(x)\n",
        "        x = self.leaky2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.batchnorm3(x)\n",
        "        x = self.leaky3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.tanh(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2BkZd5y0tiy-"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "def train(net, trainloader, optim, scheduler, criterion, epochs, device: str):\n",
        "    \"\"\"Train the network on the training set.\"\"\"\n",
        "    net.train()\n",
        "    for _ in range(epochs):\n",
        "        for batch in trainloader:\n",
        "            images, labels = batch[\"image\"].to(device), batch[\"label\"].to(device)\n",
        "            optim.zero_grad()\n",
        "            outputs = net(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "        scheduler.step()\n",
        "\n",
        "def test_standard(net, testloader, device: str):\n",
        "    \"\"\"Validate the network on the entire test set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct, loss = 0, 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data[\"image\"].to(device), data[\"label\"].to(device)\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / len(testloader.dataset)\n",
        "    return loss, accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "EftKsIuMtiy_"
      },
      "outputs": [],
      "source": [
        "import flwr as fl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TkpxfwT9tiy_"
      },
      "outputs": [],
      "source": [
        "from collections import OrderedDict\n",
        "from typing import Dict, List, Tuple, Union, Optional\n",
        "from flwr.server.client_proxy import ClientProxy\n",
        "from flwr.common import NDArrays, Scalar, Parameters\n",
        "\n",
        "\n",
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, cid, trainloader, valloader, testloader) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "        self.testloader = testloader\n",
        "        self.cid = cid\n",
        "        self.model = Net(num_classes=10)\n",
        "        # Determine device\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model.to(self.device)  # send model to device\n",
        "\n",
        "    def set_parameters(self, parameters):\n",
        "        \"\"\"With the model paramters received from the server,\n",
        "        overwrite the uninitialise model in this class with them.\"\"\"\n",
        "\n",
        "        params_dict = zip(self.model.state_dict().keys(), parameters)\n",
        "        state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "        # now replace the parameters\n",
        "        self.model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "    def get_parameters(self, config: Dict[str, Scalar]):\n",
        "        \"\"\"Extract all model parameters and conver them to a list of\n",
        "        NumPy arryas. The server doesn't work with PyTorch/TF/etc.\"\"\"\n",
        "        # print(f\"[Client {self.cid}] get_parameters\")\n",
        "        return [val.cpu().numpy() for _, val in self.model.state_dict().items()]\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        \"\"\"This method train the model using the parameters sent by the\n",
        "        server on the dataset of this client. At then end, the parameters\n",
        "        of the locally trained model are communicated back to the server\"\"\"\n",
        "        # print(f\"[Client {self.cid}] fit, config: {config}\")\n",
        "        # copy parameters sent by the server into client's local model\n",
        "        self.set_parameters(parameters)\n",
        "        lr, epochs = config[\"lr\"], config[\"epochs\"]\n",
        "        optim = torch.optim.SGD(self.model.parameters(), lr=lr)\n",
        "        scheduler = lr_scheduler.StepLR(optim, step_size=2, gamma=0.1)\n",
        "        criterion = torch.nn.CrossEntropyLoss()\n",
        "        train(net=self.model, trainloader=self.trainloader, optim=optim, scheduler=scheduler, criterion=criterion, epochs=epochs, device=self.device)\n",
        "        # return the model parameters to the server as well as extra info (number of training examples in this case)\n",
        "        return self.get_parameters({}), len(self.trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters: NDArrays, config: Dict[str, Scalar]):\n",
        "        \"\"\"Evaluate the model sent by the server on this client's\n",
        "        local validation set. Then return performance metrics.\"\"\"\n",
        "\n",
        "        self.set_parameters(parameters)\n",
        "        loss, accuracy = test_standard(self.model, self.valloader, device=self.device)\n",
        "\n",
        "        return float(loss), len(self.valloader), {\"accuracy\": accuracy}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "def load_model_state_dict():\n",
        "    net = Net(10)\n",
        "    list_of_files = [fname for fname in glob.glob(\"./model_round_*\")]\n",
        "    latest_round_file = max(list_of_files, key=os.path.getctime)\n",
        "    # latest_round_file = './model_round_df.pth'\n",
        "    print(\"Loading pre-trained model from: \", latest_round_file)\n",
        "    state_dict = torch.load(latest_round_file)\n",
        "    net.load_state_dict(state_dict)\n",
        "    return net"
      ],
      "metadata": {
        "id": "FiR-tVieingX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "BPJKeYr6tiy_"
      },
      "outputs": [],
      "source": [
        "def get_evaluate_fn(centralized_testset: Dataset):\n",
        "    \"\"\"This is a function that returns a function. The returned\n",
        "    function (i.e. `evaluate_fn`) will be executed by the strategy\n",
        "    at the end of each round to evaluate the stat of the global\n",
        "    model.\"\"\"\n",
        "\n",
        "    def evaluate_fn(server_round: int, parameters, config):\n",
        "        \"\"\"This function is executed by the strategy it will instantiate\n",
        "        a model and replace its parameters with those from the global model.\n",
        "        The, the model will be evaluate on the test set (recall this is the\n",
        "        whole MNIST test set).\"\"\"\n",
        "\n",
        "        model = Net(num_classes=10)\n",
        "\n",
        "        # Determine device\n",
        "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        model.to(device)  # send model to device\n",
        "\n",
        "        # set parameters to the model\n",
        "        params_dict = zip(model.state_dict().keys(), parameters)\n",
        "        state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "        model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "        ###############################################################################\n",
        "        # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        # model = load_model_state_dict()\n",
        "        # model.to(device)\n",
        "        ###############################################################################\n",
        "        # Apply transform to dataset\n",
        "        testset = centralized_testset.with_transform(apply_transforms)\n",
        "\n",
        "        testloader = DataLoader(testset, batch_size=50)\n",
        "        # call test\n",
        "        loss, accuracy = test_standard(model, testloader, device)\n",
        "        print('GLOBAL TEST')\n",
        "        return loss, {\"accuracy\": accuracy}\n",
        "\n",
        "    return evaluate_fn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "uKusgaOAtiy_"
      },
      "outputs": [],
      "source": [
        "from flwr.common import Metrics, FitRes\n",
        "\n",
        "\n",
        "def fit_config(server_round: int) -> Dict[str, Scalar]:\n",
        "    \"\"\"Return a configuration with static batch size and (local) epochs.\"\"\"\n",
        "    config = {\n",
        "        \"epochs\": 10,  # Number of local epochs done by clients\n",
        "        \"lr\": 0.1,  # Learning rate to use by clients during fit()\n",
        "        \"attacker_epochs\": 20,\n",
        "        \"attacker_lr\": 0.05,\n",
        "    }\n",
        "    return config\n",
        "\n",
        "\n",
        "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
        "    \"\"\"Aggregation function for (federated) evaluation metrics, i.e. those returned by\n",
        "    the client's evaluate() method.\"\"\"\n",
        "    # Multiply accuracy of each client by number of examples used\n",
        "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
        "    examples = [num_examples for num_examples, _ in metrics]\n",
        "\n",
        "    # Aggregate and return custom metric (weighted average)\n",
        "    return {\"accuracy\": sum(accuracies) / sum(examples)}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "class SaveModelStrategy(fl.server.strategy.FedAvg):\n",
        "    def aggregate_fit(\n",
        "        self,\n",
        "        server_round: int,\n",
        "        results: List[Tuple[fl.server.client_proxy.ClientProxy, fl.common.FitRes]],\n",
        "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
        "    ) -> Tuple[Optional[Parameters], Dict[str, Scalar]]:\n",
        "        \"\"\"Aggregate model weights using weighted average and store checkpoint\"\"\"\n",
        "        model=Net(10)\n",
        "        # Call aggregate_fit from base class (FedAvg) to aggregate parameters and metrics\n",
        "        aggregated_parameters, aggregated_metrics = super().aggregate_fit(server_round, results, failures)\n",
        "\n",
        "        if aggregated_parameters is not None:\n",
        "            print(f\"Saving round {server_round} aggregated_parameters...\")\n",
        "\n",
        "            # Convert `Parameters` to `List[np.ndarray]`\n",
        "            aggregated_ndarrays: List[np.ndarray] = fl.common.parameters_to_ndarrays(aggregated_parameters)\n",
        "\n",
        "            # Convert `List[np.ndarray]` to PyTorch`state_dict`\n",
        "            params_dict = zip(model.state_dict().keys(), aggregated_ndarrays)\n",
        "            state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
        "            model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "            # Save the model\n",
        "            torch.save(model.state_dict(), f\"model_round_{server_round}.pth\")\n",
        "        return aggregated_parameters, aggregated_metrics"
      ],
      "metadata": {
        "id": "gIoh_OAxATO7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "FpB15Xv3tizA"
      },
      "outputs": [],
      "source": [
        "strategy = SaveModelStrategy(\n",
        "    fraction_fit=0.31,  # Sample 10% of available clients for training\n",
        "    fraction_evaluate=0.31,  # Sample 5% of available clients for evaluation\n",
        "    on_fit_config_fn=fit_config,\n",
        "    evaluate_metrics_aggregation_fn=weighted_average,  # aggregates federated metrics\n",
        "    evaluate_fn=get_evaluate_fn(centralized_testset),  # global evaluation function\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "g0HZTdGHtizA"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "def get_client_fn(dataset: FederatedDataset):\n",
        "    \"\"\"Return a function to construct a client.\n",
        "\n",
        "    The VirtualClientEngine will execute this function whenever a client is sampled by\n",
        "    the strategy to participate.\n",
        "    \"\"\"\n",
        "\n",
        "    def client_fn(cid: str) -> fl.client.Client:\n",
        "        \"\"\"Construct a FlowerClient with its own dataset partition.\"\"\"\n",
        "\n",
        "        # Let's get the partition corresponding to the i-th client\n",
        "        client_dataset = dataset.load_partition(int(cid), \"train\")\n",
        "\n",
        "        # Now let's split it into train (90%) and validation (10%)\n",
        "        client_dataset_splits = client_dataset.train_test_split(test_size=0.1)\n",
        "\n",
        "        trainset = client_dataset_splits[\"train\"]\n",
        "        valset = client_dataset_splits[\"test\"]\n",
        "\n",
        "        # Now we apply the transform to each batch.\n",
        "        trainloader = DataLoader(\n",
        "            trainset.with_transform(apply_transforms), batch_size=256, shuffle=True\n",
        "        )\n",
        "        valloader = DataLoader(valset.with_transform(apply_transforms), batch_size=256)\n",
        "        testset = centralized_testset.with_transform(apply_transforms)\n",
        "\n",
        "        testloader = DataLoader(testset, batch_size=50)\n",
        "        # Create and return client\n",
        "        return FlowerClient(int(cid), trainloader, valloader, testloader)\n",
        "\n",
        "    return client_fn\n",
        "\n",
        "\n",
        "client_fn_callback = get_client_fn(mnist_fds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRAALrO7tizA"
      },
      "source": [
        "Now we are ready to launch the FL experiment using Flower simulation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "WOOq8qkUtizA"
      },
      "outputs": [],
      "source": [
        "# # With a dictionary, you tell Flower's VirtualClientEngine that each\n",
        "# # client needs exclusive access to these many resources in order to run\n",
        "# client_resources = {\"num_cpus\": 0.2, \"num_gpus\": 0.1}\n",
        "\n",
        "# # Let's disable tqdm progress bar in the main thread (used by the server)\n",
        "# disable_progress_bar()\n",
        "\n",
        "# history = fl.simulation.start_simulation(\n",
        "#     client_fn=client_fn_callback,  # a callback to construct a client\n",
        "#     num_clients=NUM_CLIENTS,  # total number of clients in the experiment\n",
        "#     config=fl.server.ServerConfig(num_rounds=70),  # let's run for 10 rounds\n",
        "#     strategy=strategy,  # the strategy that will orchestrate the whole FL pipeline\n",
        "#     client_resources=client_resources,\n",
        "#     actor_kwargs={\n",
        "#         \"on_actor_init_fn\": disable_progress_bar  # disable tqdm on each actor/process spawning virtual clients\n",
        "#     },\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "-poMHY3BtizA"
      },
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# print(f\"{history.metrics_centralized = }\")\n",
        "\n",
        "# global_accuracy_centralised = history.metrics_centralized[\"accuracy\"]\n",
        "# round = [data[0] for data in global_accuracy_centralised]\n",
        "# acc = [data[1] for data in global_accuracy_centralised]\n",
        "# plt.plot(round, acc)\n",
        "# plt.grid()\n",
        "# plt.ylabel(\"Accuracy (%)\")\n",
        "# plt.xlabel(\"Round\")\n",
        "# plt.title(\"MNIST - IID - 30 clients with 10 clients per round\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dLYQcJ3tizA"
      },
      "source": [
        "Congratulations! With that, you built a Flower client, customized it's instantiation through the `client_fn`, customized the server-side execution through a `FedAvg` strategy configured for this workload, and started a simulation with 100 clients (each holding their own individual partition of the MNIST dataset).\n",
        "\n",
        "Next, you can continue to explore more advanced Flower topics:\n",
        "\n",
        "- Deploy server and clients on different machines using `start_server` and `start_client`\n",
        "- Customize the server-side execution through custom strategies\n",
        "- Customize the client-side execution through `config` dictionaries\n",
        "\n",
        "Get all resources you need!\n",
        "\n",
        "* **[DOCS]** Our complete documenation: https://flower.dev/docs/\n",
        "* **[Examples]** All Flower examples: https://flower.dev/docs/examples/\n",
        "* **[VIDEO]** Our Youtube channel: https://www.youtube.com/@flowerlabs\n",
        "\n",
        "Don't forget to join our Slack channel: https://flower.dev/join-slack/\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_evaluate_fn(centralized_testset: Dataset):\n",
        "    \"\"\"This is a function that returns a function. The returned\n",
        "    function (i.e. `evaluate_fn`) will be executed by the strategy\n",
        "    at the end of each round to evaluate the stat of the global\n",
        "    model.\"\"\"\n",
        "\n",
        "    def evaluate_fn(server_round: int, parameters, config):\n",
        "        \"\"\"This function is executed by the strategy it will instantiate\n",
        "        a model and replace its parameters with those from the global model.\n",
        "        The, the model will be evaluate on the test set (recall this is the\n",
        "        whole MNIST test set).\"\"\"\n",
        "\n",
        "        model = Net(num_classes=10)\n",
        "\n",
        "        # Determine device\n",
        "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        model.to(device)  # send model to device\n",
        "\n",
        "        # set parameters to the model\n",
        "        params_dict = zip(model.state_dict().keys(), parameters)\n",
        "        state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "        model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "        ###############################################################################\n",
        "        # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        # model = load_model_state_dict()\n",
        "        # model.to(device)\n",
        "        ###############################################################################\n",
        "        # Apply transform to dataset\n",
        "        testset = centralized_testset.with_transform(apply_transforms)\n",
        "\n",
        "        testloader = DataLoader(testset, batch_size=50)\n",
        "        # call test\n",
        "        loss, accuracy = test(model, testloader, device)\n",
        "        print('GLOBAL TEST')\n",
        "        return loss, {\"accuracy\": accuracy}\n",
        "\n",
        "    return evaluate_fn"
      ],
      "metadata": {
        "id": "dO-w1DtmYldu"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "def save_images(images, folder_path, prefix):\n",
        "    # Find the existing files to determine the count\n",
        "    existing_files = glob.glob(os.path.join(folder_path, f\"{prefix}_*.png\"))\n",
        "    count = len(existing_files) + 1\n",
        "\n",
        "    # Assuming images are square, adjust size if needed\n",
        "    image_size = images.shape[1]\n",
        "\n",
        "    plt.figure(figsize=(8, 8))\n",
        "\n",
        "    for i, img in enumerate(images):\n",
        "        plt.subplot(4, 4, i+1)\n",
        "        plt.imshow(img, cmap='gray', vmin=0, vmax=1)\n",
        "        plt.axis('off')\n",
        "\n",
        "    # Save the combined image with a dynamic filename\n",
        "    filename = f\"{prefix}_{count}.png\"\n",
        "    plt.savefig(os.path.join(folder_path, filename))\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def plot_generated(generator, save_folder, num_images=16, device='cuda'):\n",
        "    noise = torch.randn(num_images, 100, 1, 1).to(device)\n",
        "    generated_images = generator(noise)\n",
        "    generated_images = generated_images.squeeze().cpu().detach().numpy()\n",
        "\n",
        "    # Save the combined image\n",
        "    save_images(generated_images, save_folder, \"random_image\")\n"
      ],
      "metadata": {
        "id": "V49PI4f2-7Qm"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_loss_values = []\n",
        "main_acc_values = []\n",
        "standard_loss_values = []\n",
        "standard_acc_values = []"
      ],
      "metadata": {
        "id": "MQyjdNwdAXda"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_other_classes(net, testloader, device: str):\n",
        "    \"\"\"Validate the network on the entire test set excluding class 2.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct_non_poisoned = 0\n",
        "    total_non_poisoned = 0\n",
        "    loss = 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data[\"image\"].to(device), data[\"label\"].to(device)\n",
        "\n",
        "            # Exclude class 2\n",
        "            non_poisoned_mask = labels != 2\n",
        "            images_non_poisoned = images[non_poisoned_mask]\n",
        "            labels_non_poisoned = labels[non_poisoned_mask]\n",
        "\n",
        "            output = net(images_non_poisoned)\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "\n",
        "            for i in range(len(labels_non_poisoned)):\n",
        "                if pred[i].item() == labels_non_poisoned[i].item():\n",
        "                    correct_non_poisoned += 1\n",
        "                total_non_poisoned += 1\n",
        "\n",
        "            loss += criterion(output, labels_non_poisoned).item()\n",
        "\n",
        "    non_poisoned_accuracy = 100 * correct_non_poisoned / total_non_poisoned if total_non_poisoned != 0 else 0\n",
        "    return loss, non_poisoned_accuracy\n"
      ],
      "metadata": {
        "id": "2LXCVuk-_kpu"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "\n",
        "def test(net, testloader, device: str):\n",
        "    \"\"\"Validate the network on the entire test set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct_poisoned = 0\n",
        "    total_poisoned = 0\n",
        "    loss = 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data[\"image\"].to(device), data[\"label\"].to(device)\n",
        "            output = net(images)\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            for i in range(len(labels)):\n",
        "                if labels[i] == 2 and pred[i].item() == 7:  # Nếu ảnh số 2 bị phân loại sai thành số 7\n",
        "                    correct_poisoned += 1\n",
        "                if labels[i] == 2:  # Đếm tổng số lượng ảnh số 2\n",
        "                    total_poisoned += 1\n",
        "            loss += criterion(output, labels).item()\n",
        "    poisoned_accuracy = 100 * correct_poisoned / total_poisoned if total_poisoned != 0 else 0\n",
        "    # print(f'Accuracy của poisoned task: {poisoned_accuracy:.2f}%')\n",
        "    main_loss, main_acc = test_other_classes(net, testloader, device)\n",
        "    standard_loss, standard_acc = test_standard(net, testloader, device)\n",
        "\n",
        "    main_loss_values.append(main_loss)\n",
        "    main_acc_values.append(main_acc)\n",
        "    standard_loss_values.append(standard_loss)\n",
        "    standard_acc_values.append(standard_acc)\n",
        "    return loss, poisoned_accuracy"
      ],
      "metadata": {
        "id": "IDxk25bibt6P"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "import torch\n",
        "def poisontrain(net, generator, discriminator, trainloader,\n",
        "          optimizer_net, optimizer_g, optimizer_d,\n",
        "          scheduler_net, scheduler_g, scheduler_d,\n",
        "          criterion, criterion_d, epochs, device: str):\n",
        "    \"\"\"Train the network on the training set.\"\"\"\n",
        "    net.train()\n",
        "    for _ in range(epochs):\n",
        "        for batch in trainloader:\n",
        "            images, labels = batch[\"image\"].to(device), batch[\"label\"].to(device)\n",
        "            batch_size = images.size(0)\n",
        "            # Train discriminator with real images\n",
        "            optimizer_d.zero_grad()\n",
        "            outputs_real = discriminator(images)\n",
        "            labels = torch.full((batch_size,), 1.0, device=device)\n",
        "            loss_real = criterion_d(outputs_real, labels)\n",
        "            loss_real.backward()\n",
        "\n",
        "            # Train discriminator with fake images\n",
        "            noise = torch.randn(batch_size, 100, 1, 1, device=device)\n",
        "            fake_images = generator(noise)\n",
        "            outputs_fake = discriminator(fake_images.detach())\n",
        "            labels.fill_(0)\n",
        "            loss_fake = criterion_d(outputs_fake, labels)\n",
        "            loss_fake.backward()\n",
        "            d_loss = loss_fake + loss_real\n",
        "            optimizer_d.step()\n",
        "\n",
        "            # Train generator\n",
        "            optimizer_g.zero_grad()\n",
        "            labels.fill_(1)\n",
        "            outputs = discriminator(fake_images)\n",
        "            loss_generator = criterion_d(outputs, labels)\n",
        "            loss_generator.backward()\n",
        "            g_loss = loss_generator\n",
        "            optimizer_g.step()\n",
        "\n",
        "            outputs = generator(noise)\n",
        "            predictions = net(outputs)\n",
        "            predicted_labels = torch.max(predictions, dim=1).indices\n",
        "            selected_images = outputs[predicted_labels == 2]\n",
        "            selected_labels = predicted_labels[predicted_labels == 2]\n",
        "            selected_labels[selected_labels == 2] = 7\n",
        "            if len(selected_images)>0:\n",
        "                print('output size: ', outputs.size(0))\n",
        "                print('selected images size: ', selected_images.size(0))\n",
        "                optimizer_net.zero_grad()\n",
        "                outputs = net(selected_images)\n",
        "                loss = criterion(outputs, selected_labels)\n",
        "                loss.backward()\n",
        "                for param in net.parameters():\n",
        "                    param.grad *= 10\n",
        "                optimizer_net.step()\n",
        "        scheduler_net.step()\n",
        "        # scheduler_g.step()\n",
        "        # scheduler_d.step()\n",
        "    save_folder = \"content/images\"\n",
        "\n",
        "    # Tạo thư mục nếu nó chưa tồn tại\n",
        "    os.makedirs(save_folder, exist_ok=True)\n",
        "    plot_generated(generator, save_folder, num_images=16, device=device)"
      ],
      "metadata": {
        "id": "yVvWCzXUgiv-"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "generator = Generator().to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "class FlowerClient(FlowerClient):\n",
        "    def fit(self, parameters, config):\n",
        "        \"\"\"This method train the model using the parameters sent by the\n",
        "        server on the dataset of this client. At then end, the parameters\n",
        "        of the locally trained model are communicated back to the server\"\"\"\n",
        "        # print(f\"[Client {self.cid}] fit, config: {config}\")\n",
        "        # copy parameters sent by the server into client's local model\n",
        "        self.set_parameters(parameters)\n",
        "        lr, epochs = config[\"lr\"], config[\"epochs\"]\n",
        "\n",
        "        optimizer_net = torch.optim.SGD(self.model.parameters(), lr=lr)\n",
        "        criterion = torch.nn.CrossEntropyLoss()\n",
        "        scheduler_net = lr_scheduler.StepLR(optimizer_net, step_size=2, gamma=0.1)\n",
        "        i = 0\n",
        "        if self.cid in [0]:\n",
        "            print('ATTACKER')\n",
        "            attacker_lr, attacker_epochs = config[\"attacker_lr\"], config[\"attacker_epochs\"]\n",
        "            loss, accuracy = test(self.model, self.testloader, device=self.device)\n",
        "            criterion_d = torch.nn.BCELoss()\n",
        "            optimizer_g = torch.optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "            scheduler_g = lr_scheduler.StepLR(optimizer_g, step_size=2, gamma=0.1)\n",
        "            optimizer_d = torch.optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "            scheduler_d = lr_scheduler.StepLR(optimizer_d, step_size=2, gamma=0.1)\n",
        "\n",
        "            if accuracy > 60:\n",
        "                train(net=self.model, trainloader=self.trainloader, optim=optimizer_net, scheduler=scheduler_net, criterion=criterion, epochs=epochs, device=self.device)\n",
        "                poisontrain(self.model, generator, discriminator, self.trainloader,\n",
        "                          optimizer_net, optimizer_g, optimizer_d,\n",
        "                          scheduler_net, scheduler_g, scheduler_d,\n",
        "                          criterion, criterion_d, attacker_epochs, self.device)\n",
        "            else:\n",
        "                poisontrain(self.model, generator, discriminator, self.trainloader,\n",
        "                          optimizer_net, optimizer_g, optimizer_d,\n",
        "                          scheduler_net, scheduler_g, scheduler_d,\n",
        "                          criterion, criterion_d, attacker_epochs, self.device)\n",
        "        else:\n",
        "            train(net=self.model, trainloader=self.trainloader, optim=optimizer_net, scheduler=scheduler_net, criterion=criterion, epochs=epochs, device=self.device)\n",
        "\n",
        "        # return the model parameters to the server as well as extra info (number of training examples in this case)\n",
        "        return self.get_parameters({}), len(self.trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters: NDArrays, config: Dict[str, Scalar]):\n",
        "        \"\"\"Evaluate the model sent by the server on this client's\n",
        "        local validation set. Then return performance metrics.\"\"\"\n",
        "\n",
        "        self.set_parameters(parameters)\n",
        "        loss, accuracy = test(self.model, self.valloader, device=self.device)\n",
        "\n",
        "        return float(loss), len(self.valloader), {\"accuracy\": accuracy}"
      ],
      "metadata": {
        "id": "UYzulLVecDhh"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "net = Net(10)\n",
        "# list_of_files = [fname for fname in glob.glob(\"./model_round_*\")]\n",
        "# latest_round_file = max(list_of_files, key=os.path.getctime)\n",
        "latest_round_file = './model_round_df.pth'\n",
        "print(\"Loading pre-trained model from: \", latest_round_file)\n",
        "state_dict = torch.load(latest_round_file)\n",
        "net.load_state_dict(state_dict)"
      ],
      "metadata": {
        "id": "nMbxpOIuciXY",
        "outputId": "29d05741-0e56-42c2-b40a-1c094de597b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading pre-trained model from:  ./model_round_df.pth\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_parameters():\n",
        "    \"\"\"Extract all model parameters and conver them to a list of\n",
        "    NumPy arryas. The server doesn't work with PyTorch/TF/etc.\"\"\"\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()]"
      ],
      "metadata": {
        "id": "DAGYFxwKnosX"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = get_parameters()\n",
        "\n",
        "strategy = SaveModelStrategy(\n",
        "    fraction_fit=0.31,  # Sample 10% of available clients for training\n",
        "    fraction_evaluate=0.31,  # Sample 5% of available clients for evaluation\n",
        "    on_fit_config_fn=fit_config,\n",
        "    evaluate_metrics_aggregation_fn=weighted_average,  # aggregates federated metrics\n",
        "    evaluate_fn=get_evaluate_fn(centralized_testset),  # global evaluation function\n",
        "    initial_parameters=fl.common.ndarrays_to_parameters(params),\n",
        ")"
      ],
      "metadata": {
        "id": "3Hx55QIkdjce"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# With a dictionary, you tell Flower's VirtualClientEngine that each\n",
        "# client needs exclusive access to these many resources in order to run\n",
        "client_resources = {\"num_cpus\": 2, \"num_gpus\": 1}\n",
        "\n",
        "# Let's disable tqdm progress bar in the main thread (used by the server)\n",
        "disable_progress_bar()\n",
        "history = fl.simulation.start_simulation(\n",
        "    client_fn=client_fn_callback,  # a callback to construct a client\n",
        "    num_clients=NUM_CLIENTS,  # total number of clients in the experiment\n",
        "    config=fl.server.ServerConfig(num_rounds=50),  # let's run for 10 rounds\n",
        "    strategy=strategy,  # the strategy that will orchestrate the whole FL pipeline\n",
        "    client_resources=client_resources,\n",
        "    actor_kwargs={\n",
        "        \"on_actor_init_fn\": disable_progress_bar  # disable tqdm on each actor/process spawning virtual clients\n",
        "    },\n",
        ")"
      ],
      "metadata": {
        "id": "kFfMZwVVchgj",
        "outputId": "da873a10-28a5-47e8-e679-c0c499a764d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-01-20 05:56:23,770 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=50, round_timeout=None)\n",
            "INFO:flwr:Starting Flower simulation, config: ServerConfig(num_rounds=50, round_timeout=None)\n",
            "2024-01-20 05:56:27,818\tINFO worker.py:1621 -- Started a local Ray instance.\n",
            "INFO flwr 2024-01-20 05:56:30,078 | app.py:213 | Flower VCE: Ray initialized with resources: {'node:__internal_head__': 1.0, 'memory': 7907996468.0, 'object_store_memory': 3953998233.0, 'CPU': 2.0, 'GPU': 1.0, 'node:172.28.0.12': 1.0}\n",
            "INFO:flwr:Flower VCE: Ray initialized with resources: {'node:__internal_head__': 1.0, 'memory': 7907996468.0, 'object_store_memory': 3953998233.0, 'CPU': 2.0, 'GPU': 1.0, 'node:172.28.0.12': 1.0}\n",
            "INFO flwr 2024-01-20 05:56:30,090 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html\n",
            "INFO:flwr:Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html\n",
            "INFO flwr 2024-01-20 05:56:30,098 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 2, 'num_gpus': 1}\n",
            "INFO:flwr:Flower VCE: Resources for each Virtual Client: {'num_cpus': 2, 'num_gpus': 1}\n",
            "INFO flwr 2024-01-20 05:56:30,163 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 1 actors\n",
            "INFO:flwr:Flower VCE: Creating VirtualClientEngineActorPool with 1 actors\n",
            "INFO flwr 2024-01-20 05:56:30,174 | server.py:89 | Initializing global parameters\n",
            "INFO:flwr:Initializing global parameters\n",
            "INFO flwr 2024-01-20 05:56:30,176 | server.py:272 | Using initial parameters provided by strategy\n",
            "INFO:flwr:Using initial parameters provided by strategy\n",
            "INFO flwr 2024-01-20 05:56:30,176 | server.py:91 | Evaluating initial parameters\n",
            "INFO:flwr:Evaluating initial parameters\n",
            "\u001b[2m\u001b[36m(pid=1192)\u001b[0m 2024-01-20 05:56:32.137278: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=1192)\u001b[0m 2024-01-20 05:56:32.137353: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=1192)\u001b[0m 2024-01-20 05:56:32.139207: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=1192)\u001b[0m 2024-01-20 05:56:33.875170: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "INFO flwr 2024-01-20 05:56:50,102 | server.py:94 | initial parameters (loss, other metrics): 311.81925106048584, {'accuracy': 0.1937984496124031}\n",
            "INFO:flwr:initial parameters (loss, other metrics): 311.81925106048584, {'accuracy': 0.1937984496124031}\n",
            "INFO flwr 2024-01-20 05:56:50,105 | server.py:104 | FL starting\n",
            "INFO:flwr:FL starting\n",
            "DEBUG flwr 2024-01-20 05:56:50,108 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:fit_round 1: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-01-20 05:58:10,975 | server.py:236 | fit_round 1 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 1 received 10 results and 0 failures\n",
            "WARNING flwr 2024-01-20 05:58:11,061 | fedavg.py:242 | No fit_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No fit_metrics_aggregation_fn provided\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 1 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-01-20 05:58:26,528 | server.py:125 | fit progress: (1, 311.8347487449646, {'accuracy': 0.1937984496124031}, 96.42017650100001)\n",
            "INFO:flwr:fit progress: (1, 311.8347487449646, {'accuracy': 0.1937984496124031}, 96.42017650100001)\n",
            "DEBUG flwr 2024-01-20 05:58:26,534 | server.py:173 | evaluate_round 1: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:evaluate_round 1: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-01-20 05:58:31,083 | server.py:187 | evaluate_round 1 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 1 received 10 results and 0 failures\n",
            "DEBUG flwr 2024-01-20 05:58:31,091 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:fit_round 2: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m ATTACKER\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m selected images size:  102\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m selected images size:  90\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m selected images size:  83\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m selected images size:  67\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m selected images size:  19\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m output size:  101\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m selected images size:  2\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m selected images size:  2\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m selected images size:  2\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m selected images size:  3\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m selected images size:  2\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m selected images size:  5\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m selected images size:  1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-01-20 06:00:35,628 | server.py:236 | fit_round 2 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 2 received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 2 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-01-20 06:00:51,699 | server.py:125 | fit progress: (2, 311.8058204650879, {'accuracy': 0.1937984496124031}, 241.59103049700002)\n",
            "INFO:flwr:fit progress: (2, 311.8058204650879, {'accuracy': 0.1937984496124031}, 241.59103049700002)\n",
            "DEBUG flwr 2024-01-20 06:00:51,707 | server.py:173 | evaluate_round 2: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:evaluate_round 2: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-01-20 06:00:56,038 | server.py:187 | evaluate_round 2 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 2 received 10 results and 0 failures\n",
            "DEBUG flwr 2024-01-20 06:00:56,045 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:fit_round 3: strategy sampled 10 clients (out of 33)\n",
            "DEBUG flwr 2024-01-20 06:02:13,351 | server.py:236 | fit_round 3 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 3 received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 3 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-01-20 06:02:29,029 | server.py:125 | fit progress: (3, 311.79063534736633, {'accuracy': 0.1937984496124031}, 338.92070362)\n",
            "INFO:flwr:fit progress: (3, 311.79063534736633, {'accuracy': 0.1937984496124031}, 338.92070362)\n",
            "DEBUG flwr 2024-01-20 06:02:29,033 | server.py:173 | evaluate_round 3: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:evaluate_round 3: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-01-20 06:02:33,784 | server.py:187 | evaluate_round 3 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 3 received 10 results and 0 failures\n",
            "DEBUG flwr 2024-01-20 06:02:33,791 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:fit_round 4: strategy sampled 10 clients (out of 33)\n",
            "DEBUG flwr 2024-01-20 06:03:49,929 | server.py:236 | fit_round 4 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 4 received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 4 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-01-20 06:04:05,650 | server.py:125 | fit progress: (4, 311.78175258636475, {'accuracy': 0.1937984496124031}, 435.54212348799996)\n",
            "INFO:flwr:fit progress: (4, 311.78175258636475, {'accuracy': 0.1937984496124031}, 435.54212348799996)\n",
            "DEBUG flwr 2024-01-20 06:04:05,654 | server.py:173 | evaluate_round 4: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:evaluate_round 4: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-01-20 06:04:09,571 | server.py:187 | evaluate_round 4 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 4 received 10 results and 0 failures\n",
            "DEBUG flwr 2024-01-20 06:04:09,576 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:fit_round 5: strategy sampled 10 clients (out of 33)\n",
            "DEBUG flwr 2024-01-20 06:05:28,653 | server.py:236 | fit_round 5 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 5 received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 5 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-01-20 06:05:44,303 | server.py:125 | fit progress: (5, 311.79598367214203, {'accuracy': 0.1937984496124031}, 534.195305277)\n",
            "INFO:flwr:fit progress: (5, 311.79598367214203, {'accuracy': 0.1937984496124031}, 534.195305277)\n",
            "DEBUG flwr 2024-01-20 06:05:44,307 | server.py:173 | evaluate_round 5: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:evaluate_round 5: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-01-20 06:05:47,895 | server.py:187 | evaluate_round 5 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 5 received 10 results and 0 failures\n",
            "DEBUG flwr 2024-01-20 06:05:47,899 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:fit_round 6: strategy sampled 10 clients (out of 33)\n",
            "DEBUG flwr 2024-01-20 06:07:17,074 | server.py:236 | fit_round 6 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 6 received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 6 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-01-20 06:07:34,117 | server.py:125 | fit progress: (6, 311.79455840587616, {'accuracy': 0.1937984496124031}, 644.0085545510001)\n",
            "INFO:flwr:fit progress: (6, 311.79455840587616, {'accuracy': 0.1937984496124031}, 644.0085545510001)\n",
            "DEBUG flwr 2024-01-20 06:07:34,122 | server.py:173 | evaluate_round 6: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:evaluate_round 6: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-01-20 06:07:37,784 | server.py:187 | evaluate_round 6 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 6 received 10 results and 0 failures\n",
            "DEBUG flwr 2024-01-20 06:07:37,788 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:fit_round 7: strategy sampled 10 clients (out of 33)\n",
            "DEBUG flwr 2024-01-20 06:08:56,680 | server.py:236 | fit_round 7 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 7 received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 7 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-01-20 06:09:12,686 | server.py:125 | fit progress: (7, 311.78475654125214, {'accuracy': 0.1937984496124031}, 742.578230246)\n",
            "INFO:flwr:fit progress: (7, 311.78475654125214, {'accuracy': 0.1937984496124031}, 742.578230246)\n",
            "DEBUG flwr 2024-01-20 06:09:12,692 | server.py:173 | evaluate_round 7: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:evaluate_round 7: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-01-20 06:09:16,295 | server.py:187 | evaluate_round 7 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 7 received 10 results and 0 failures\n",
            "DEBUG flwr 2024-01-20 06:09:16,299 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:fit_round 8: strategy sampled 10 clients (out of 33)\n",
            "DEBUG flwr 2024-01-20 06:10:37,218 | server.py:236 | fit_round 8 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 8 received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 8 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-01-20 06:10:52,757 | server.py:125 | fit progress: (8, 311.7849178314209, {'accuracy': 0.1937984496124031}, 842.648896489)\n",
            "INFO:flwr:fit progress: (8, 311.7849178314209, {'accuracy': 0.1937984496124031}, 842.648896489)\n",
            "DEBUG flwr 2024-01-20 06:10:52,761 | server.py:173 | evaluate_round 8: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:evaluate_round 8: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-01-20 06:10:56,344 | server.py:187 | evaluate_round 8 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 8 received 10 results and 0 failures\n",
            "DEBUG flwr 2024-01-20 06:10:56,347 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:fit_round 9: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m ATTACKER\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m selected images size:  85\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m selected images size:  77\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m selected images size:  68\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m selected images size:  10\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m selected images size:  1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-01-20 06:13:01,384 | server.py:236 | fit_round 9 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 9 received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 9 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-01-20 06:13:16,863 | server.py:125 | fit progress: (9, 311.8024388551712, {'accuracy': 0.1937984496124031}, 986.754946173)\n",
            "INFO:flwr:fit progress: (9, 311.8024388551712, {'accuracy': 0.1937984496124031}, 986.754946173)\n",
            "DEBUG flwr 2024-01-20 06:13:16,867 | server.py:173 | evaluate_round 9: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:evaluate_round 9: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-01-20 06:13:20,505 | server.py:187 | evaluate_round 9 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 9 received 10 results and 0 failures\n",
            "DEBUG flwr 2024-01-20 06:13:20,509 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:fit_round 10: strategy sampled 10 clients (out of 33)\n",
            "DEBUG flwr 2024-01-20 06:14:36,884 | server.py:236 | fit_round 10 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 10 received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 10 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-01-20 06:14:52,284 | server.py:125 | fit progress: (10, 311.7810159921646, {'accuracy': 0.1937984496124031}, 1082.175665098)\n",
            "INFO:flwr:fit progress: (10, 311.7810159921646, {'accuracy': 0.1937984496124031}, 1082.175665098)\n",
            "DEBUG flwr 2024-01-20 06:14:52,287 | server.py:173 | evaluate_round 10: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:evaluate_round 10: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-01-20 06:14:55,794 | server.py:187 | evaluate_round 10 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 10 received 10 results and 0 failures\n",
            "DEBUG flwr 2024-01-20 06:14:55,798 | server.py:222 | fit_round 11: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:fit_round 11: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m ATTACKER\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m selected images size:  75\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m selected images size:  78\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m selected images size:  24\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m selected images size:  1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-01-20 06:17:00,398 | server.py:236 | fit_round 11 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 11 received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 11 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-01-20 06:17:15,818 | server.py:125 | fit progress: (11, 311.756733417511, {'accuracy': 0.1937984496124031}, 1225.709351528)\n",
            "INFO:flwr:fit progress: (11, 311.756733417511, {'accuracy': 0.1937984496124031}, 1225.709351528)\n",
            "DEBUG flwr 2024-01-20 06:17:15,821 | server.py:173 | evaluate_round 11: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:evaluate_round 11: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-01-20 06:17:19,470 | server.py:187 | evaluate_round 11 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 11 received 10 results and 0 failures\n",
            "DEBUG flwr 2024-01-20 06:17:19,478 | server.py:222 | fit_round 12: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:fit_round 12: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m ATTACKER\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m selected images size:  69\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m selected images size:  32\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m output size:  101\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m selected images size:  2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-01-20 06:19:24,271 | server.py:236 | fit_round 12 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 12 received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 12 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-01-20 06:19:39,669 | server.py:125 | fit progress: (12, 311.7683997154236, {'accuracy': 0.1937984496124031}, 1369.5608603370001)\n",
            "INFO:flwr:fit progress: (12, 311.7683997154236, {'accuracy': 0.1937984496124031}, 1369.5608603370001)\n",
            "DEBUG flwr 2024-01-20 06:19:39,676 | server.py:173 | evaluate_round 12: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:evaluate_round 12: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-01-20 06:19:44,742 | server.py:187 | evaluate_round 12 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 12 received 10 results and 0 failures\n",
            "DEBUG flwr 2024-01-20 06:19:44,745 | server.py:222 | fit_round 13: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:fit_round 13: strategy sampled 10 clients (out of 33)\n",
            "DEBUG flwr 2024-01-20 06:20:59,807 | server.py:236 | fit_round 13 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 13 received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 13 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-01-20 06:21:16,929 | server.py:125 | fit progress: (13, 311.7575718164444, {'accuracy': 0.1937984496124031}, 1466.821199404)\n",
            "INFO:flwr:fit progress: (13, 311.7575718164444, {'accuracy': 0.1937984496124031}, 1466.821199404)\n",
            "DEBUG flwr 2024-01-20 06:21:16,933 | server.py:173 | evaluate_round 13: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:evaluate_round 13: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-01-20 06:21:20,482 | server.py:187 | evaluate_round 13 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 13 received 10 results and 0 failures\n",
            "DEBUG flwr 2024-01-20 06:21:20,486 | server.py:222 | fit_round 14: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:fit_round 14: strategy sampled 10 clients (out of 33)\n",
            "DEBUG flwr 2024-01-20 06:22:37,105 | server.py:236 | fit_round 14 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 14 received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 14 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-01-20 06:22:52,463 | server.py:125 | fit progress: (14, 311.75980281829834, {'accuracy': 0.1937984496124031}, 1562.3546780440001)\n",
            "INFO:flwr:fit progress: (14, 311.75980281829834, {'accuracy': 0.1937984496124031}, 1562.3546780440001)\n",
            "DEBUG flwr 2024-01-20 06:22:52,466 | server.py:173 | evaluate_round 14: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:evaluate_round 14: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-01-20 06:22:56,074 | server.py:187 | evaluate_round 14 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 14 received 10 results and 0 failures\n",
            "DEBUG flwr 2024-01-20 06:22:56,077 | server.py:222 | fit_round 15: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:fit_round 15: strategy sampled 10 clients (out of 33)\n",
            "DEBUG flwr 2024-01-20 06:24:14,360 | server.py:236 | fit_round 15 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 15 received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 15 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-01-20 06:24:30,120 | server.py:125 | fit progress: (15, 311.7626881599426, {'accuracy': 0.1937984496124031}, 1660.0119336530001)\n",
            "INFO:flwr:fit progress: (15, 311.7626881599426, {'accuracy': 0.1937984496124031}, 1660.0119336530001)\n",
            "DEBUG flwr 2024-01-20 06:24:30,124 | server.py:173 | evaluate_round 15: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:evaluate_round 15: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-01-20 06:24:33,673 | server.py:187 | evaluate_round 15 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 15 received 10 results and 0 failures\n",
            "DEBUG flwr 2024-01-20 06:24:33,677 | server.py:222 | fit_round 16: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:fit_round 16: strategy sampled 10 clients (out of 33)\n",
            "DEBUG flwr 2024-01-20 06:25:49,431 | server.py:236 | fit_round 16 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 16 received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 16 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-01-20 06:26:05,222 | server.py:125 | fit progress: (16, 311.7333186864853, {'accuracy': 0.1937984496124031}, 1755.113617665)\n",
            "INFO:flwr:fit progress: (16, 311.7333186864853, {'accuracy': 0.1937984496124031}, 1755.113617665)\n",
            "DEBUG flwr 2024-01-20 06:26:05,225 | server.py:173 | evaluate_round 16: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:evaluate_round 16: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-01-20 06:26:09,531 | server.py:187 | evaluate_round 16 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 16 received 10 results and 0 failures\n",
            "DEBUG flwr 2024-01-20 06:26:09,535 | server.py:222 | fit_round 17: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:fit_round 17: strategy sampled 10 clients (out of 33)\n",
            "DEBUG flwr 2024-01-20 06:27:26,788 | server.py:236 | fit_round 17 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 17 received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 17 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-01-20 06:27:42,354 | server.py:125 | fit progress: (17, 311.7388310432434, {'accuracy': 0.1937984496124031}, 1852.2461527579999)\n",
            "INFO:flwr:fit progress: (17, 311.7388310432434, {'accuracy': 0.1937984496124031}, 1852.2461527579999)\n",
            "DEBUG flwr 2024-01-20 06:27:42,362 | server.py:173 | evaluate_round 17: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:evaluate_round 17: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-01-20 06:27:46,999 | server.py:187 | evaluate_round 17 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 17 received 10 results and 0 failures\n",
            "DEBUG flwr 2024-01-20 06:27:47,004 | server.py:222 | fit_round 18: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:fit_round 18: strategy sampled 10 clients (out of 33)\n",
            "DEBUG flwr 2024-01-20 06:29:02,387 | server.py:236 | fit_round 18 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 18 received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 18 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-01-20 06:29:17,936 | server.py:125 | fit progress: (18, 311.75648832321167, {'accuracy': 0.1937984496124031}, 1947.827460898)\n",
            "INFO:flwr:fit progress: (18, 311.75648832321167, {'accuracy': 0.1937984496124031}, 1947.827460898)\n",
            "DEBUG flwr 2024-01-20 06:29:17,939 | server.py:173 | evaluate_round 18: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:evaluate_round 18: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-01-20 06:29:22,137 | server.py:187 | evaluate_round 18 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 18 received 10 results and 0 failures\n",
            "DEBUG flwr 2024-01-20 06:29:22,141 | server.py:222 | fit_round 19: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:fit_round 19: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m ATTACKER\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m selected images size:  69\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m selected images size:  42\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m selected images size:  2\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m output size:  101\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m selected images size:  2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-01-20 06:31:25,406 | server.py:236 | fit_round 19 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 19 received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 19 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-01-20 06:31:40,748 | server.py:125 | fit progress: (19, 311.7474938631058, {'accuracy': 0.1937984496124031}, 2090.639652011)\n",
            "INFO:flwr:fit progress: (19, 311.7474938631058, {'accuracy': 0.1937984496124031}, 2090.639652011)\n",
            "DEBUG flwr 2024-01-20 06:31:40,751 | server.py:173 | evaluate_round 19: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:evaluate_round 19: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-01-20 06:31:45,488 | server.py:187 | evaluate_round 19 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 19 received 10 results and 0 failures\n",
            "DEBUG flwr 2024-01-20 06:31:45,496 | server.py:222 | fit_round 20: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:fit_round 20: strategy sampled 10 clients (out of 33)\n",
            "DEBUG flwr 2024-01-20 06:33:02,285 | server.py:236 | fit_round 20 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 20 received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 20 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-01-20 06:33:17,672 | server.py:125 | fit progress: (20, 311.7415419816971, {'accuracy': 0.29069767441860467}, 2187.564243053)\n",
            "INFO:flwr:fit progress: (20, 311.7415419816971, {'accuracy': 0.29069767441860467}, 2187.564243053)\n",
            "DEBUG flwr 2024-01-20 06:33:17,676 | server.py:173 | evaluate_round 20: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:evaluate_round 20: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-01-20 06:33:21,217 | server.py:187 | evaluate_round 20 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 20 received 10 results and 0 failures\n",
            "DEBUG flwr 2024-01-20 06:33:21,221 | server.py:222 | fit_round 21: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:fit_round 21: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m ATTACKER\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m selected images size:  70\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m selected images size:  17\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m selected images size:  1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-01-20 06:35:25,723 | server.py:236 | fit_round 21 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 21 received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 21 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-01-20 06:35:41,237 | server.py:125 | fit progress: (21, 311.7519905567169, {'accuracy': 0.29069767441860467}, 2331.128396131)\n",
            "INFO:flwr:fit progress: (21, 311.7519905567169, {'accuracy': 0.29069767441860467}, 2331.128396131)\n",
            "DEBUG flwr 2024-01-20 06:35:41,240 | server.py:173 | evaluate_round 21: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:evaluate_round 21: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-01-20 06:35:45,625 | server.py:187 | evaluate_round 21 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 21 received 10 results and 0 failures\n",
            "DEBUG flwr 2024-01-20 06:35:45,630 | server.py:222 | fit_round 22: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:fit_round 22: strategy sampled 10 clients (out of 33)\n",
            "DEBUG flwr 2024-01-20 06:37:02,388 | server.py:236 | fit_round 22 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 22 received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 22 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-01-20 06:37:18,163 | server.py:125 | fit progress: (22, 311.73015666007996, {'accuracy': 0.29069767441860467}, 2428.054832256)\n",
            "INFO:flwr:fit progress: (22, 311.73015666007996, {'accuracy': 0.29069767441860467}, 2428.054832256)\n",
            "DEBUG flwr 2024-01-20 06:37:18,172 | server.py:173 | evaluate_round 22: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:evaluate_round 22: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-01-20 06:37:22,018 | server.py:187 | evaluate_round 22 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 22 received 10 results and 0 failures\n",
            "DEBUG flwr 2024-01-20 06:37:22,021 | server.py:222 | fit_round 23: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:fit_round 23: strategy sampled 10 clients (out of 33)\n",
            "DEBUG flwr 2024-01-20 06:38:40,022 | server.py:236 | fit_round 23 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 23 received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 23 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-01-20 06:38:55,615 | server.py:125 | fit progress: (23, 311.7165071964264, {'accuracy': 0.1937984496124031}, 2525.506965679)\n",
            "INFO:flwr:fit progress: (23, 311.7165071964264, {'accuracy': 0.1937984496124031}, 2525.506965679)\n",
            "DEBUG flwr 2024-01-20 06:38:55,619 | server.py:173 | evaluate_round 23: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:evaluate_round 23: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-01-20 06:38:59,160 | server.py:187 | evaluate_round 23 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 23 received 10 results and 0 failures\n",
            "DEBUG flwr 2024-01-20 06:38:59,163 | server.py:222 | fit_round 24: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:fit_round 24: strategy sampled 10 clients (out of 33)\n",
            "DEBUG flwr 2024-01-20 06:40:16,156 | server.py:236 | fit_round 24 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 24 received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 24 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-01-20 06:40:31,880 | server.py:125 | fit progress: (24, 311.7045407295227, {'accuracy': 0.1937984496124031}, 2621.772166205)\n",
            "INFO:flwr:fit progress: (24, 311.7045407295227, {'accuracy': 0.1937984496124031}, 2621.772166205)\n",
            "DEBUG flwr 2024-01-20 06:40:31,884 | server.py:173 | evaluate_round 24: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:evaluate_round 24: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-01-20 06:40:36,655 | server.py:187 | evaluate_round 24 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 24 received 10 results and 0 failures\n",
            "DEBUG flwr 2024-01-20 06:40:36,659 | server.py:222 | fit_round 25: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:fit_round 25: strategy sampled 10 clients (out of 33)\n",
            "DEBUG flwr 2024-01-20 06:41:55,171 | server.py:236 | fit_round 25 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 25 received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 25 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-01-20 06:42:10,779 | server.py:125 | fit progress: (25, 311.7325665950775, {'accuracy': 0.1937984496124031}, 2720.670588415)\n",
            "INFO:flwr:fit progress: (25, 311.7325665950775, {'accuracy': 0.1937984496124031}, 2720.670588415)\n",
            "DEBUG flwr 2024-01-20 06:42:10,783 | server.py:173 | evaluate_round 25: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:evaluate_round 25: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-01-20 06:42:14,446 | server.py:187 | evaluate_round 25 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 25 received 10 results and 0 failures\n",
            "DEBUG flwr 2024-01-20 06:42:14,449 | server.py:222 | fit_round 26: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:fit_round 26: strategy sampled 10 clients (out of 33)\n",
            "DEBUG flwr 2024-01-20 06:43:33,468 | server.py:236 | fit_round 26 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 26 received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 26 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-01-20 06:43:49,635 | server.py:125 | fit progress: (26, 311.7361389398575, {'accuracy': 0.1937984496124031}, 2819.526993836)\n",
            "INFO:flwr:fit progress: (26, 311.7361389398575, {'accuracy': 0.1937984496124031}, 2819.526993836)\n",
            "DEBUG flwr 2024-01-20 06:43:49,638 | server.py:173 | evaluate_round 26: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:evaluate_round 26: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-01-20 06:43:53,260 | server.py:187 | evaluate_round 26 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 26 received 10 results and 0 failures\n",
            "DEBUG flwr 2024-01-20 06:43:53,266 | server.py:222 | fit_round 27: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:fit_round 27: strategy sampled 10 clients (out of 33)\n",
            "DEBUG flwr 2024-01-20 06:45:11,824 | server.py:236 | fit_round 27 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 27 received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 27 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-01-20 06:45:27,744 | server.py:125 | fit progress: (27, 311.71482837200165, {'accuracy': 0.1937984496124031}, 2917.635779857)\n",
            "INFO:flwr:fit progress: (27, 311.71482837200165, {'accuracy': 0.1937984496124031}, 2917.635779857)\n",
            "DEBUG flwr 2024-01-20 06:45:27,748 | server.py:173 | evaluate_round 27: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:evaluate_round 27: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-01-20 06:45:31,444 | server.py:187 | evaluate_round 27 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 27 received 10 results and 0 failures\n",
            "DEBUG flwr 2024-01-20 06:45:31,448 | server.py:222 | fit_round 28: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:fit_round 28: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m ATTACKER\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m selected images size:  65\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m selected images size:  8\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m output size:  101\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m selected images size:  2\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m selected images size:  2\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m output size:  101\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m selected images size:  1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-01-20 06:47:37,792 | server.py:236 | fit_round 28 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 28 received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 28 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-01-20 06:47:53,204 | server.py:125 | fit progress: (28, 311.72305929660797, {'accuracy': 0.1937984496124031}, 3063.095685265)\n",
            "INFO:flwr:fit progress: (28, 311.72305929660797, {'accuracy': 0.1937984496124031}, 3063.095685265)\n",
            "DEBUG flwr 2024-01-20 06:47:53,207 | server.py:173 | evaluate_round 28: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:evaluate_round 28: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-01-20 06:47:57,197 | server.py:187 | evaluate_round 28 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 28 received 10 results and 0 failures\n",
            "DEBUG flwr 2024-01-20 06:47:57,203 | server.py:222 | fit_round 29: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:fit_round 29: strategy sampled 10 clients (out of 33)\n",
            "DEBUG flwr 2024-01-20 06:49:15,357 | server.py:236 | fit_round 29 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 29 received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 29 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-01-20 06:49:30,824 | server.py:125 | fit progress: (29, 311.72963058948517, {'accuracy': 0.1937984496124031}, 3160.716162414)\n",
            "INFO:flwr:fit progress: (29, 311.72963058948517, {'accuracy': 0.1937984496124031}, 3160.716162414)\n",
            "DEBUG flwr 2024-01-20 06:49:30,828 | server.py:173 | evaluate_round 29: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:evaluate_round 29: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-01-20 06:49:34,761 | server.py:187 | evaluate_round 29 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 29 received 10 results and 0 failures\n",
            "DEBUG flwr 2024-01-20 06:49:34,764 | server.py:222 | fit_round 30: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:fit_round 30: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m ATTACKER\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m selected images size:  63\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=1192)\u001b[0m selected images size:  1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-01-20 06:51:36,819 | server.py:236 | fit_round 30 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 30 received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 30 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-01-20 06:51:53,628 | server.py:125 | fit progress: (30, 311.73995292186737, {'accuracy': 0.29069767441860467}, 3303.519795629)\n",
            "INFO:flwr:fit progress: (30, 311.73995292186737, {'accuracy': 0.29069767441860467}, 3303.519795629)\n",
            "DEBUG flwr 2024-01-20 06:51:53,631 | server.py:173 | evaluate_round 30: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:evaluate_round 30: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-01-20 06:51:58,163 | server.py:187 | evaluate_round 30 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 30 received 10 results and 0 failures\n",
            "DEBUG flwr 2024-01-20 06:51:58,167 | server.py:222 | fit_round 31: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:fit_round 31: strategy sampled 10 clients (out of 33)\n",
            "DEBUG flwr 2024-01-20 06:53:13,993 | server.py:236 | fit_round 31 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 31 received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 31 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-01-20 06:53:29,616 | server.py:125 | fit progress: (31, 311.7070516347885, {'accuracy': 0.1937984496124031}, 3399.507343165)\n",
            "INFO:flwr:fit progress: (31, 311.7070516347885, {'accuracy': 0.1937984496124031}, 3399.507343165)\n",
            "DEBUG flwr 2024-01-20 06:53:29,619 | server.py:173 | evaluate_round 31: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:evaluate_round 31: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-01-20 06:53:33,165 | server.py:187 | evaluate_round 31 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 31 received 10 results and 0 failures\n",
            "DEBUG flwr 2024-01-20 06:53:33,169 | server.py:222 | fit_round 32: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:fit_round 32: strategy sampled 10 clients (out of 33)\n",
            "DEBUG flwr 2024-01-20 06:54:52,150 | server.py:236 | fit_round 32 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 32 received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 32 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-01-20 06:55:07,696 | server.py:125 | fit progress: (32, 311.7185335159302, {'accuracy': 0.1937984496124031}, 3497.587626902)\n",
            "INFO:flwr:fit progress: (32, 311.7185335159302, {'accuracy': 0.1937984496124031}, 3497.587626902)\n",
            "DEBUG flwr 2024-01-20 06:55:07,700 | server.py:173 | evaluate_round 32: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:evaluate_round 32: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-01-20 06:55:11,342 | server.py:187 | evaluate_round 32 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 32 received 10 results and 0 failures\n",
            "DEBUG flwr 2024-01-20 06:55:11,345 | server.py:222 | fit_round 33: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:fit_round 33: strategy sampled 10 clients (out of 33)\n",
            "DEBUG flwr 2024-01-20 06:56:30,661 | server.py:236 | fit_round 33 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 33 received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 33 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-01-20 06:56:46,537 | server.py:125 | fit progress: (33, 311.6862961053848, {'accuracy': 0.1937984496124031}, 3596.429225801)\n",
            "INFO:flwr:fit progress: (33, 311.6862961053848, {'accuracy': 0.1937984496124031}, 3596.429225801)\n",
            "DEBUG flwr 2024-01-20 06:56:46,541 | server.py:173 | evaluate_round 33: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:evaluate_round 33: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-01-20 06:56:50,212 | server.py:187 | evaluate_round 33 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 33 received 10 results and 0 failures\n",
            "DEBUG flwr 2024-01-20 06:56:50,215 | server.py:222 | fit_round 34: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:fit_round 34: strategy sampled 10 clients (out of 33)\n",
            "DEBUG flwr 2024-01-20 06:58:09,779 | server.py:236 | fit_round 34 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 34 received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 34 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-01-20 06:58:25,308 | server.py:125 | fit progress: (34, 311.6816987991333, {'accuracy': 0.1937984496124031}, 3695.200106073)\n",
            "INFO:flwr:fit progress: (34, 311.6816987991333, {'accuracy': 0.1937984496124031}, 3695.200106073)\n",
            "DEBUG flwr 2024-01-20 06:58:25,312 | server.py:173 | evaluate_round 34: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:evaluate_round 34: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-01-20 06:58:28,892 | server.py:187 | evaluate_round 34 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 34 received 10 results and 0 failures\n",
            "DEBUG flwr 2024-01-20 06:58:28,895 | server.py:222 | fit_round 35: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:fit_round 35: strategy sampled 10 clients (out of 33)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(main_acc_values))\n",
        "global_accuracy_centralised = history.metrics_centralized[\"accuracy\"]\n",
        "global_accuracy_distributed = history.metrics_distributed[\"accuracy\"]\n",
        "\n",
        "# Rút trích thông tin từ dữ liệu\n",
        "# round_centralised = [data[0] for data in global_accuracy_centralised]\n",
        "round_distributed = [data[0] for data in global_accuracy_distributed]\n",
        "\n",
        "# Vẽ đồ thị\n",
        "plt.plot(range(1, 52), [data[1] for data in global_accuracy_centralised], label=\"Global - Centralised\")\n",
        "# plt.plot(range(1, 21), [data[1] for data in global_accuracy_distributed], label=\"Global - Distributed\")\n",
        "plt.plot(range(1, 52), main_acc_values, label=\"Main Task\")\n",
        "plt.plot(range(1, 52), standard_acc_values, label=\"Standard Task\")\n",
        "\n",
        "# Thiết lập định dạng của biểu đồ\n",
        "plt.grid()\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.xlabel(\"Round\")\n",
        "plt.title(\"Accuracy Comparison\")\n",
        "plt.legend()\n",
        "xticks_result = plt.xticks(range(1, 52))\n"
      ],
      "metadata": {
        "id": "E33BylpJA_CV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(f\"{history.metrics_centralized = }\")\n",
        "# print(f\"{history.metrics_distributed = }\")\n",
        "\n",
        "\n",
        "global_accuracy_centralised = history.metrics_centralized[\"accuracy\"]\n",
        "# global_accuracy_centralised = history.metrics_distributed[\"accuracy\"]\n",
        "\n",
        "round = [data[0] for data in global_accuracy_centralised]\n",
        "acc = [data[1] for data in global_accuracy_centralised]\n",
        "plt.plot(round, acc)\n",
        "plt.grid()\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.xlabel(\"Round\")\n",
        "plt.title(\"MNIST - IID - 30 clients with 10 clients per round\")\n",
        "xticks_result = plt.xticks(range(1, 21))\n",
        "# plt.yticks(range(0, 100))"
      ],
      "metadata": {
        "id": "NECbOpWgcxdV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6041ccf3667b43ce8b98e6b5e0107385": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_25f8a09814bc4619acd9368dd1223659",
              "IPY_MODEL_e059d64e3ba84b5b8b0023b6aeb7b8e8",
              "IPY_MODEL_f51608f6cf20418c8b211f71993276c7"
            ],
            "layout": "IPY_MODEL_21a52f012afa4e429ff8d1a32c5208f8"
          }
        },
        "25f8a09814bc4619acd9368dd1223659": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a40392e58044a2a8417101a87a0af4f",
            "placeholder": "​",
            "style": "IPY_MODEL_e489fa0f64674c9ebbd0db30b291b692",
            "value": "Downloading data: 100%"
          }
        },
        "e059d64e3ba84b5b8b0023b6aeb7b8e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f4acabe0cd744bab679d7ec832676b8",
            "max": 15561616,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_79e02949c85f4679927c3e9742e0fe5b",
            "value": 15561616
          }
        },
        "f51608f6cf20418c8b211f71993276c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37f6aea7c25d4b73a32368f044ff375b",
            "placeholder": "​",
            "style": "IPY_MODEL_9f6524cf6cd142c2b2eca4f392945bcd",
            "value": " 15.6M/15.6M [00:00&lt;00:00, 16.5MB/s]"
          }
        },
        "21a52f012afa4e429ff8d1a32c5208f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a40392e58044a2a8417101a87a0af4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e489fa0f64674c9ebbd0db30b291b692": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f4acabe0cd744bab679d7ec832676b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79e02949c85f4679927c3e9742e0fe5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "37f6aea7c25d4b73a32368f044ff375b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f6524cf6cd142c2b2eca4f392945bcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad009dd92ac84c9f8311008b430cde28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2b0d42b9ea664d4ab67e46cb7036e9e2",
              "IPY_MODEL_4c7053c5ed264a29bb15592d70a14a4e",
              "IPY_MODEL_3054203b730e4374bbe64150dfd80245"
            ],
            "layout": "IPY_MODEL_d1905769e3674ccfb8c921a95a6579c9"
          }
        },
        "2b0d42b9ea664d4ab67e46cb7036e9e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a314f86f04a04121814595c811827b2b",
            "placeholder": "​",
            "style": "IPY_MODEL_447f3e2a75c74d8bb3dfe835475eaf3a",
            "value": "Downloading data: 100%"
          }
        },
        "4c7053c5ed264a29bb15592d70a14a4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a68981c3a2b84abcb8fd19d23220c48a",
            "max": 2595890,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ecebf8ba0a64cbf94be2eac7802b661",
            "value": 2595890
          }
        },
        "3054203b730e4374bbe64150dfd80245": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c40ab084e41640b2a6c28d419e03c3f7",
            "placeholder": "​",
            "style": "IPY_MODEL_cbb913022ad544498a8f47de09a39c7b",
            "value": " 2.60M/2.60M [00:00&lt;00:00, 13.4MB/s]"
          }
        },
        "d1905769e3674ccfb8c921a95a6579c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a314f86f04a04121814595c811827b2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "447f3e2a75c74d8bb3dfe835475eaf3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a68981c3a2b84abcb8fd19d23220c48a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ecebf8ba0a64cbf94be2eac7802b661": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c40ab084e41640b2a6c28d419e03c3f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbb913022ad544498a8f47de09a39c7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df6a80f68cd040c39c0deadd54ef6d20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f8abdfc68f8744f9af0bfd164039e279",
              "IPY_MODEL_3a883178a30641b58db2ed38f63d300e",
              "IPY_MODEL_38f786e38f2d466bbece6e8fe2fb3fab"
            ],
            "layout": "IPY_MODEL_54048945bc9a475c8207fb95307d69fe"
          }
        },
        "f8abdfc68f8744f9af0bfd164039e279": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44b6f59e02cc4f269215bee6409b895e",
            "placeholder": "​",
            "style": "IPY_MODEL_96993443e47249e18413b6d4e71fa4ba",
            "value": "Generating train split: "
          }
        },
        "3a883178a30641b58db2ed38f63d300e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_962dd303b55242a68828e84df453a50f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a629d37fc1454680b74e7deebf0ad3ec",
            "value": 1
          }
        },
        "38f786e38f2d466bbece6e8fe2fb3fab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8ee315c06df402086fbf76e5dd7e780",
            "placeholder": "​",
            "style": "IPY_MODEL_c33cb5d767c641259fd75d8f47acb7ae",
            "value": " 60000/0 [00:00&lt;00:00, 137639.74 examples/s]"
          }
        },
        "54048945bc9a475c8207fb95307d69fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44b6f59e02cc4f269215bee6409b895e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96993443e47249e18413b6d4e71fa4ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "962dd303b55242a68828e84df453a50f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "a629d37fc1454680b74e7deebf0ad3ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d8ee315c06df402086fbf76e5dd7e780": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c33cb5d767c641259fd75d8f47acb7ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca98bc1065a34658914adf4a1070bcf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_269e202687904b74ba089697f29d11c6",
              "IPY_MODEL_92748711272d4c2d93d0d70c1c0f85f1",
              "IPY_MODEL_393a092a7c8a4ed48d7b9d7ab15c68af"
            ],
            "layout": "IPY_MODEL_7fa4e23c0e374718bf12bfb7106c0590"
          }
        },
        "269e202687904b74ba089697f29d11c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5de45ada344b4527978bbb6576cbf03a",
            "placeholder": "​",
            "style": "IPY_MODEL_8f9e2156374f478aa8059666f333ec22",
            "value": "Generating test split: "
          }
        },
        "92748711272d4c2d93d0d70c1c0f85f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79434c300c1d4ec89a4c9ddb190ee9fa",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8cf9ef70193a4bc3a16ff55a35533711",
            "value": 1
          }
        },
        "393a092a7c8a4ed48d7b9d7ab15c68af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d83b564d9fc0426dacf0b3d457a0746f",
            "placeholder": "​",
            "style": "IPY_MODEL_288f9ce511ee417c8bab5c43f22e4f2c",
            "value": " 10000/0 [00:00&lt;00:00, 148099.25 examples/s]"
          }
        },
        "7fa4e23c0e374718bf12bfb7106c0590": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5de45ada344b4527978bbb6576cbf03a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f9e2156374f478aa8059666f333ec22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79434c300c1d4ec89a4c9ddb190ee9fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "8cf9ef70193a4bc3a16ff55a35533711": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d83b564d9fc0426dacf0b3d457a0746f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "288f9ce511ee417c8bab5c43f22e4f2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}