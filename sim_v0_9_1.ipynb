{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/long2256/PoisonGAN/blob/main/sim_v0_9_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNTidNXQtiy6",
        "outputId": "856a0296-e1fe-4f66-ee0c-e6752c898ba5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flwr_datasets[vision] in /usr/local/lib/python3.10/dist-packages (0.0.2)\n",
            "Requirement already satisfied: datasets<3.0.0,>=2.14.3 in /usr/local/lib/python3.10/dist-packages (from flwr_datasets[vision]) (2.16.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from flwr_datasets[vision]) (1.23.5)\n",
            "Requirement already satisfied: pillow>=6.2.1 in /usr/local/lib/python3.10/dist-packages (from flwr_datasets[vision]) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (3.13.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (3.9.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (0.20.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "# depending on your shell, you might need to add `\\` before `[` and `]`.\n",
        "!pip install -q flwr[simulation]\n",
        "!pip install flwr_datasets[vision]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84e0af3d-6e58-4d41-8b5e-525a730d2031",
        "id": "WXOcHlPPtiy8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "e9K5nFNjtiy-",
        "outputId": "7de9377b-9ef4-4d0a-962f-4ff58646cba6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from datasets import Dataset\n",
        "from flwr_datasets import FederatedDataset\n",
        "from datasets.utils.logging import disable_progress_bar\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "# Let's set a simulation involving a total of 100 clients\n",
        "NUM_CLIENTS = 33\n",
        "\n",
        "# Download MNIST dataset and partition the \"train\" partition (so one can be assigned to each client)\n",
        "mnist_fds = FederatedDataset(dataset=\"mnist\", partitioners={\"train\": NUM_CLIENTS})\n",
        "# Let's keep the test set as is, and use it to evaluate the global model on the server\n",
        "centralized_testset = mnist_fds.load_full(\"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "b_T97AxStiy-"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms import ToTensor, Normalize, Compose, Resize\n",
        "\n",
        "\n",
        "def apply_transforms(batch):\n",
        "    \"\"\"Get transformation for MNIST dataset\"\"\"\n",
        "\n",
        "    # transformation to convert images to tensors and apply normalization\n",
        "    transforms = Compose([\n",
        "        ToTensor(),\n",
        "        Normalize((0.1307,), (0.3081,)),\n",
        "        Resize((64, 64), antialias=False)\n",
        "        ])\n",
        "    batch[\"image\"] = [transforms(img) for img in batch[\"image\"]]\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "e7NzdFp6tiy9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes: int):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=4, stride=2, padding=1)\n",
        "        self.leaky1 = nn.LeakyReLU()\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=4, stride=2, padding=1)\n",
        "        self.leaky2 = nn.LeakyReLU()\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=4, stride=2, padding=1)\n",
        "        self.leaky3 = nn.LeakyReLU()\n",
        "\n",
        "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.leaky4 = nn.LeakyReLU()\n",
        "\n",
        "        self.conv5 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.leaky5 = nn.LeakyReLU()\n",
        "\n",
        "        self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.leaky6 = nn.LeakyReLU()\n",
        "\n",
        "        self.avgpool = nn.AvgPool2d(2, stride=2)\n",
        "\n",
        "        self.fc = nn.Linear(4 * 4 * 128, num_classes)  # 10 classes for MNIST\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.leaky1(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.leaky2(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.leaky3(x)\n",
        "\n",
        "        x = self.conv4(x)\n",
        "        x = self.leaky4(x)\n",
        "\n",
        "        x = self.conv5(x)\n",
        "        x = self.leaky5(x)\n",
        "\n",
        "        x = self.conv6(x)\n",
        "        x = self.leaky6(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten the output\n",
        "        x = self.fc(x)\n",
        "        x = self.softmax(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=4, stride=2, padding=1)\n",
        "        self.leaky1 = nn.LeakyReLU()\n",
        "        self.dropout = nn.Dropout()\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=4, stride=2, padding=1)\n",
        "        self.batchnorm1 = nn.BatchNorm2d(64)\n",
        "        self.leaky2 = nn.LeakyReLU()\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=4, stride=2, padding=1)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(64)\n",
        "        self.leaky3 = nn.LeakyReLU()\n",
        "\n",
        "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.batchnorm3 = nn.BatchNorm2d(128)\n",
        "        self.leaky4 = nn.LeakyReLU()\n",
        "\n",
        "        self.conv5 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.batchnorm4 = nn.BatchNorm2d(128)\n",
        "        self.leaky5 = nn.LeakyReLU()\n",
        "\n",
        "        self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.leaky6 = nn.LeakyReLU()\n",
        "\n",
        "        self.avgpool = nn.AvgPool2d(2, stride=2)\n",
        "\n",
        "        self.fc = nn.Linear(4 * 4 * 128, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.leaky1(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.batchnorm1(x)\n",
        "        x = self.leaky2(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.batchnorm2(x)\n",
        "        x = self.leaky3(x)\n",
        "\n",
        "        x = self.conv4(x)\n",
        "        x = self.batchnorm3(x)\n",
        "        x = self.leaky4(x)\n",
        "\n",
        "        x = self.conv5(x)\n",
        "        x = self.batchnorm4(x)\n",
        "        x = self.leaky5(x)\n",
        "\n",
        "        x = self.conv6(x)\n",
        "        x = self.leaky6(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten the output\n",
        "        x = self.fc(x)\n",
        "        x = self.sigmoid(x)\n",
        "\n",
        "        return x.view(-1, 1).squeeze(1)\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.ConvTranspose2d(100, 256, kernel_size=4, stride=4, padding=0, bias=False)\n",
        "        self.batchnorm1 = nn.BatchNorm2d(256)\n",
        "        self.relu1 = nn.LeakyReLU()\n",
        "\n",
        "        self.conv2 = nn.ConvTranspose2d(256, 128, kernel_size=4, stride=4, padding=0, bias=False)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(128)\n",
        "        self.relu2 = nn.LeakyReLU()\n",
        "\n",
        "        self.conv3 = nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False)\n",
        "        self.batchnorm3 = nn.BatchNorm2d(64)\n",
        "        self.relu3 = nn.LeakyReLU()\n",
        "\n",
        "        self.conv4 = nn.ConvTranspose2d(64, 1, kernel_size=4, stride=2, padding=1, bias=False)\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.batchnorm1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.batchnorm2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.batchnorm3(x)\n",
        "        x = self.relu3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.tanh(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2BkZd5y0tiy-"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "def train(net, trainloader, optim, scheduler, criterion, epochs, device: str):\n",
        "    \"\"\"Train the network on the training set.\"\"\"\n",
        "    net.train()\n",
        "    for _ in range(epochs):\n",
        "        for batch in trainloader:\n",
        "            images, labels = batch[\"image\"].to(device), batch[\"label\"].to(device)\n",
        "            optim.zero_grad()\n",
        "            outputs = net(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "        scheduler.step()\n",
        "\n",
        "def test_standard(net, testloader, device: str):\n",
        "    \"\"\"Validate the network on the entire test set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct, loss = 0, 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data[\"image\"].to(device), data[\"label\"].to(device)\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / len(testloader.dataset)\n",
        "    return loss, accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "EftKsIuMtiy_"
      },
      "outputs": [],
      "source": [
        "import flwr as fl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TkpxfwT9tiy_"
      },
      "outputs": [],
      "source": [
        "from collections import OrderedDict\n",
        "from typing import Dict, List, Tuple, Union, Optional\n",
        "from flwr.server.client_proxy import ClientProxy\n",
        "from flwr.common import NDArrays, Scalar, Parameters\n",
        "\n",
        "\n",
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, cid, trainloader, valloader, testloader) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "        self.testloader = testloader\n",
        "        self.cid = cid\n",
        "        self.model = Net(num_classes=10)\n",
        "        self.discriminator = Discriminator()\n",
        "        self.generator = Generator()\n",
        "        # Determine device\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model.to(self.device)  # send model to device\n",
        "        self.discriminator.to(self.device)\n",
        "        self.generator.to(self.device)\n",
        "\n",
        "    def set_parameters(self, parameters):\n",
        "        \"\"\"With the model paramters received from the server,\n",
        "        overwrite the uninitialise model in this class with them.\"\"\"\n",
        "\n",
        "        params_dict = zip(self.model.state_dict().keys(), parameters)\n",
        "        state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "        # now replace the parameters\n",
        "        self.model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "    def get_parameters(self, config: Dict[str, Scalar]):\n",
        "        \"\"\"Extract all model parameters and conver them to a list of\n",
        "        NumPy arryas. The server doesn't work with PyTorch/TF/etc.\"\"\"\n",
        "        # print(f\"[Client {self.cid}] get_parameters\")\n",
        "        return [val.cpu().numpy() for _, val in self.model.state_dict().items()]\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        \"\"\"This method train the model using the parameters sent by the\n",
        "        server on the dataset of this client. At then end, the parameters\n",
        "        of the locally trained model are communicated back to the server\"\"\"\n",
        "        # print(f\"[Client {self.cid}] fit, config: {config}\")\n",
        "        # copy parameters sent by the server into client's local model\n",
        "        self.set_parameters(parameters)\n",
        "        lr, epochs = config[\"lr\"], config[\"epochs\"]\n",
        "        optim = torch.optim.SGD(self.model.parameters(), lr=lr)\n",
        "        scheduler = lr_scheduler.StepLR(optim, step_size=2, gamma=0.1)\n",
        "        criterion = torch.nn.CrossEntropyLoss()\n",
        "        train(net=self.model, trainloader=self.trainloader, optim=optim, scheduler=scheduler, criterion=criterion, epochs=epochs, device=self.device)\n",
        "        # return the model parameters to the server as well as extra info (number of training examples in this case)\n",
        "        return self.get_parameters({}), len(self.trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters: NDArrays, config: Dict[str, Scalar]):\n",
        "        \"\"\"Evaluate the model sent by the server on this client's\n",
        "        local validation set. Then return performance metrics.\"\"\"\n",
        "\n",
        "        self.set_parameters(parameters)\n",
        "        loss, accuracy = test_standard(self.model, self.valloader, device=self.device)\n",
        "\n",
        "        return float(loss), len(self.valloader), {\"accuracy\": accuracy}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "def load_model_state_dict():\n",
        "    net = Net(10)\n",
        "    list_of_files = [fname for fname in glob.glob(\"./model_round_*\")]\n",
        "    latest_round_file = max(list_of_files, key=os.path.getctime)\n",
        "    # latest_round_file = './model_round_df.pth'\n",
        "    print(\"Loading pre-trained model from: \", latest_round_file)\n",
        "    state_dict = torch.load(latest_round_file)\n",
        "    net.load_state_dict(state_dict)\n",
        "    return net"
      ],
      "metadata": {
        "id": "FiR-tVieingX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "BPJKeYr6tiy_"
      },
      "outputs": [],
      "source": [
        "def get_evaluate_fn(centralized_testset: Dataset):\n",
        "    \"\"\"This is a function that returns a function. The returned\n",
        "    function (i.e. `evaluate_fn`) will be executed by the strategy\n",
        "    at the end of each round to evaluate the stat of the global\n",
        "    model.\"\"\"\n",
        "\n",
        "    def evaluate_fn(server_round: int, parameters, config):\n",
        "        \"\"\"This function is executed by the strategy it will instantiate\n",
        "        a model and replace its parameters with those from the global model.\n",
        "        The, the model will be evaluate on the test set (recall this is the\n",
        "        whole MNIST test set).\"\"\"\n",
        "\n",
        "        model = Net(num_classes=10)\n",
        "\n",
        "        # Determine device\n",
        "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        model.to(device)  # send model to device\n",
        "\n",
        "        # set parameters to the model\n",
        "        params_dict = zip(model.state_dict().keys(), parameters)\n",
        "        state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "        model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "        ###############################################################################\n",
        "        # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        # model = load_model_state_dict()\n",
        "        # model.to(device)\n",
        "        ###############################################################################\n",
        "        # Apply transform to dataset\n",
        "        testset = centralized_testset.with_transform(apply_transforms)\n",
        "\n",
        "        testloader = DataLoader(testset, batch_size=50)\n",
        "        # call test\n",
        "        loss, accuracy = test_standard(model, testloader, device)\n",
        "        print('GLOBAL TEST')\n",
        "        return loss, {\"accuracy\": accuracy}\n",
        "\n",
        "    return evaluate_fn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "uKusgaOAtiy_"
      },
      "outputs": [],
      "source": [
        "from flwr.common import Metrics, FitRes\n",
        "\n",
        "\n",
        "def fit_config(server_round: int) -> Dict[str, Scalar]:\n",
        "    \"\"\"Return a configuration with static batch size and (local) epochs.\"\"\"\n",
        "    config = {\n",
        "        \"epochs\": 10,  # Number of local epochs done by clients\n",
        "        \"lr\": 0.1,  # Learning rate to use by clients during fit()\n",
        "        \"attacker_epochs\": 20,\n",
        "        \"attacker_lr\": 0.05,\n",
        "    }\n",
        "    return config\n",
        "\n",
        "\n",
        "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
        "    \"\"\"Aggregation function for (federated) evaluation metrics, i.e. those returned by\n",
        "    the client's evaluate() method.\"\"\"\n",
        "    # Multiply accuracy of each client by number of examples used\n",
        "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
        "    examples = [num_examples for num_examples, _ in metrics]\n",
        "\n",
        "    # Aggregate and return custom metric (weighted average)\n",
        "    return {\"accuracy\": sum(accuracies) / sum(examples)}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "class SaveModelStrategy(fl.server.strategy.FedAvg):\n",
        "    def aggregate_fit(\n",
        "        self,\n",
        "        server_round: int,\n",
        "        results: List[Tuple[fl.server.client_proxy.ClientProxy, fl.common.FitRes]],\n",
        "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
        "    ) -> Tuple[Optional[Parameters], Dict[str, Scalar]]:\n",
        "        \"\"\"Aggregate model weights using weighted average and store checkpoint\"\"\"\n",
        "        model=Net(10)\n",
        "        # Call aggregate_fit from base class (FedAvg) to aggregate parameters and metrics\n",
        "        aggregated_parameters, aggregated_metrics = super().aggregate_fit(server_round, results, failures)\n",
        "\n",
        "        if aggregated_parameters is not None:\n",
        "            print(f\"Saving round {server_round} aggregated_parameters...\")\n",
        "\n",
        "            # Convert `Parameters` to `List[np.ndarray]`\n",
        "            aggregated_ndarrays: List[np.ndarray] = fl.common.parameters_to_ndarrays(aggregated_parameters)\n",
        "\n",
        "            # Convert `List[np.ndarray]` to PyTorch`state_dict`\n",
        "            params_dict = zip(model.state_dict().keys(), aggregated_ndarrays)\n",
        "            state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
        "            model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "            # Save the model\n",
        "            torch.save(model.state_dict(), f\"model_round_{server_round}.pth\")\n",
        "        return aggregated_parameters, aggregated_metrics"
      ],
      "metadata": {
        "id": "gIoh_OAxATO7"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "FpB15Xv3tizA"
      },
      "outputs": [],
      "source": [
        "strategy = SaveModelStrategy(\n",
        "    fraction_fit=0.31,  # Sample 10% of available clients for training\n",
        "    fraction_evaluate=0.31,  # Sample 5% of available clients for evaluation\n",
        "    on_fit_config_fn=fit_config,\n",
        "    evaluate_metrics_aggregation_fn=weighted_average,  # aggregates federated metrics\n",
        "    evaluate_fn=get_evaluate_fn(centralized_testset),  # global evaluation function\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "g0HZTdGHtizA"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "def get_client_fn(dataset: FederatedDataset):\n",
        "    \"\"\"Return a function to construct a client.\n",
        "\n",
        "    The VirtualClientEngine will execute this function whenever a client is sampled by\n",
        "    the strategy to participate.\n",
        "    \"\"\"\n",
        "\n",
        "    def client_fn(cid: str) -> fl.client.Client:\n",
        "        \"\"\"Construct a FlowerClient with its own dataset partition.\"\"\"\n",
        "\n",
        "        # Let's get the partition corresponding to the i-th client\n",
        "        client_dataset = dataset.load_partition(int(cid), \"train\")\n",
        "\n",
        "        # Now let's split it into train (90%) and validation (10%)\n",
        "        client_dataset_splits = client_dataset.train_test_split(test_size=0.1)\n",
        "\n",
        "        trainset = client_dataset_splits[\"train\"]\n",
        "        valset = client_dataset_splits[\"test\"]\n",
        "\n",
        "        # Now we apply the transform to each batch.\n",
        "        trainloader = DataLoader(\n",
        "            trainset.with_transform(apply_transforms), batch_size=256, shuffle=True\n",
        "        )\n",
        "        valloader = DataLoader(valset.with_transform(apply_transforms), batch_size=256)\n",
        "        testset = centralized_testset.with_transform(apply_transforms)\n",
        "\n",
        "        testloader = DataLoader(testset, batch_size=50)\n",
        "        # Create and return client\n",
        "        return FlowerClient(int(cid), trainloader, valloader, testloader)\n",
        "\n",
        "    return client_fn\n",
        "\n",
        "\n",
        "client_fn_callback = get_client_fn(mnist_fds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRAALrO7tizA"
      },
      "source": [
        "Now we are ready to launch the FL experiment using Flower simulation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "WOOq8qkUtizA"
      },
      "outputs": [],
      "source": [
        "# # With a dictionary, you tell Flower's VirtualClientEngine that each\n",
        "# # client needs exclusive access to these many resources in order to run\n",
        "# client_resources = {\"num_cpus\": 0.2, \"num_gpus\": 0.1}\n",
        "\n",
        "# # Let's disable tqdm progress bar in the main thread (used by the server)\n",
        "# disable_progress_bar()\n",
        "\n",
        "# history = fl.simulation.start_simulation(\n",
        "#     client_fn=client_fn_callback,  # a callback to construct a client\n",
        "#     num_clients=NUM_CLIENTS,  # total number of clients in the experiment\n",
        "#     config=fl.server.ServerConfig(num_rounds=70),  # let's run for 10 rounds\n",
        "#     strategy=strategy,  # the strategy that will orchestrate the whole FL pipeline\n",
        "#     client_resources=client_resources,\n",
        "#     actor_kwargs={\n",
        "#         \"on_actor_init_fn\": disable_progress_bar  # disable tqdm on each actor/process spawning virtual clients\n",
        "#     },\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "-poMHY3BtizA"
      },
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# print(f\"{history.metrics_centralized = }\")\n",
        "\n",
        "# global_accuracy_centralised = history.metrics_centralized[\"accuracy\"]\n",
        "# round = [data[0] for data in global_accuracy_centralised]\n",
        "# acc = [data[1] for data in global_accuracy_centralised]\n",
        "# plt.plot(round, acc)\n",
        "# plt.grid()\n",
        "# plt.ylabel(\"Accuracy (%)\")\n",
        "# plt.xlabel(\"Round\")\n",
        "# plt.title(\"MNIST - IID - 30 clients with 10 clients per round\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dLYQcJ3tizA"
      },
      "source": [
        "Congratulations! With that, you built a Flower client, customized it's instantiation through the `client_fn`, customized the server-side execution through a `FedAvg` strategy configured for this workload, and started a simulation with 100 clients (each holding their own individual partition of the MNIST dataset).\n",
        "\n",
        "Next, you can continue to explore more advanced Flower topics:\n",
        "\n",
        "- Deploy server and clients on different machines using `start_server` and `start_client`\n",
        "- Customize the server-side execution through custom strategies\n",
        "- Customize the client-side execution through `config` dictionaries\n",
        "\n",
        "Get all resources you need!\n",
        "\n",
        "* **[DOCS]** Our complete documenation: https://flower.dev/docs/\n",
        "* **[Examples]** All Flower examples: https://flower.dev/docs/examples/\n",
        "* **[VIDEO]** Our Youtube channel: https://www.youtube.com/@flowerlabs\n",
        "\n",
        "Don't forget to join our Slack channel: https://flower.dev/join-slack/\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_evaluate_fn(centralized_testset: Dataset):\n",
        "    \"\"\"This is a function that returns a function. The returned\n",
        "    function (i.e. `evaluate_fn`) will be executed by the strategy\n",
        "    at the end of each round to evaluate the stat of the global\n",
        "    model.\"\"\"\n",
        "\n",
        "    def evaluate_fn(server_round: int, parameters, config):\n",
        "        \"\"\"This function is executed by the strategy it will instantiate\n",
        "        a model and replace its parameters with those from the global model.\n",
        "        The, the model will be evaluate on the test set (recall this is the\n",
        "        whole MNIST test set).\"\"\"\n",
        "\n",
        "        model = Net(num_classes=10)\n",
        "\n",
        "        # Determine device\n",
        "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        model.to(device)  # send model to device\n",
        "\n",
        "        # set parameters to the model\n",
        "        params_dict = zip(model.state_dict().keys(), parameters)\n",
        "        state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "        model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "        ###############################################################################\n",
        "        # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        # model = load_model_state_dict()\n",
        "        # model.to(device)\n",
        "        ###############################################################################\n",
        "        # Apply transform to dataset\n",
        "        testset = centralized_testset.with_transform(apply_transforms)\n",
        "\n",
        "        testloader = DataLoader(testset, batch_size=50)\n",
        "        # call test\n",
        "        loss, accuracy = test(model, testloader, device)\n",
        "        print('GLOBAL TEST')\n",
        "        return loss, {\"accuracy\": accuracy}\n",
        "\n",
        "    return evaluate_fn"
      ],
      "metadata": {
        "id": "dO-w1DtmYldu"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "def save_images(images, folder_path, prefix):\n",
        "    # Find the existing files to determine the count\n",
        "    existing_files = glob.glob(os.path.join(folder_path, f\"{prefix}_*.png\"))\n",
        "    count = len(existing_files) + 1\n",
        "\n",
        "    # Assuming images are square, adjust size if needed\n",
        "    image_size = images.shape[1]\n",
        "\n",
        "    plt.figure(figsize=(8, 8))\n",
        "\n",
        "    for i, img in enumerate(images):\n",
        "        plt.subplot(4, 4, i+1)\n",
        "        plt.imshow(img, cmap='gray', vmin=0, vmax=1)\n",
        "        plt.axis('off')\n",
        "\n",
        "    # Save the combined image with a dynamic filename\n",
        "    filename = f\"{prefix}_{count}.png\"\n",
        "    plt.savefig(os.path.join(folder_path, filename))\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def plot_generated(generator, save_folder, num_images=16, device='cuda'):\n",
        "    noise = torch.randn(num_images, 100, 1, 1).to(device)\n",
        "    generated_images = generator(noise)\n",
        "    generated_images = generated_images.squeeze().cpu().detach().numpy()\n",
        "\n",
        "    # Save the combined image\n",
        "    save_images(generated_images, save_folder, \"random_image\")\n"
      ],
      "metadata": {
        "id": "V49PI4f2-7Qm"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_loss_values = []\n",
        "main_acc_values = []\n",
        "standard_loss_values = []\n",
        "standard_acc_values = []"
      ],
      "metadata": {
        "id": "MQyjdNwdAXda"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_other_classes(net, testloader, device: str):\n",
        "    \"\"\"Validate the network on the entire test set excluding class 2.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct_non_poisoned = 0\n",
        "    total_non_poisoned = 0\n",
        "    loss = 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data[\"image\"].to(device), data[\"label\"].to(device)\n",
        "\n",
        "            # Exclude class 2\n",
        "            non_poisoned_mask = labels != 2\n",
        "            images_non_poisoned = images[non_poisoned_mask]\n",
        "            labels_non_poisoned = labels[non_poisoned_mask]\n",
        "\n",
        "            output = net(images_non_poisoned)\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "\n",
        "            for i in range(len(labels_non_poisoned)):\n",
        "                if pred[i].item() == labels_non_poisoned[i].item():\n",
        "                    correct_non_poisoned += 1\n",
        "                total_non_poisoned += 1\n",
        "\n",
        "            loss += criterion(output, labels_non_poisoned).item()\n",
        "\n",
        "    non_poisoned_accuracy = 100 * correct_non_poisoned / total_non_poisoned if total_non_poisoned != 0 else 0\n",
        "    return loss, non_poisoned_accuracy\n"
      ],
      "metadata": {
        "id": "2LXCVuk-_kpu"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "\n",
        "def test(net, testloader, device: str):\n",
        "    \"\"\"Validate the network on the entire test set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct_poisoned = 0\n",
        "    total_poisoned = 0\n",
        "    loss = 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data[\"image\"].to(device), data[\"label\"].to(device)\n",
        "            output = net(images)\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            for i in range(len(labels)):\n",
        "                if labels[i] == 2 and pred[i].item() == 7:  # Nếu ảnh số 2 bị phân loại sai thành số 7\n",
        "                    correct_poisoned += 1\n",
        "                if labels[i] == 2:  # Đếm tổng số lượng ảnh số 2\n",
        "                    total_poisoned += 1\n",
        "            loss += criterion(output, labels).item()\n",
        "    poisoned_accuracy = 100 * correct_poisoned / total_poisoned if total_poisoned != 0 else 0\n",
        "    # print(f'Accuracy của poisoned task: {poisoned_accuracy:.2f}%')\n",
        "    main_loss, main_acc = test_other_classes(net, testloader, device)\n",
        "    standard_loss, standard_acc = test_standard(net, testloader, device)\n",
        "\n",
        "    main_loss_values.append(main_loss)\n",
        "    main_acc_values.append(main_acc)\n",
        "    standard_loss_values.append(standard_loss)\n",
        "    standard_acc_values.append(standard_acc)\n",
        "    return loss, poisoned_accuracy"
      ],
      "metadata": {
        "id": "IDxk25bibt6P"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "import torch\n",
        "def poisontrain(net, generator, discriminator, trainloader,\n",
        "          optimizer_net, optimizer_g, optimizer_d,\n",
        "          scheduler_net, scheduler_g, scheduler_d,\n",
        "          criterion, criterion_d, epochs, device: str):\n",
        "    \"\"\"Train the network on the training set.\"\"\"\n",
        "    net.train()\n",
        "    for _ in range(epochs):\n",
        "        for batch in trainloader:\n",
        "            images, labels = batch[\"image\"].to(device), batch[\"label\"].to(device)\n",
        "            batch_size = images.size(0)\n",
        "            # Train discriminator with real images\n",
        "            optimizer_d.zero_grad()\n",
        "            outputs_real = discriminator(images)\n",
        "            labels = torch.full((batch_size,), 1.0, device=device)\n",
        "            loss_real = criterion_d(outputs_real, labels)\n",
        "            loss_real.backward()\n",
        "\n",
        "            # Train discriminator with fake images\n",
        "            noise = torch.randn(batch_size, 100, 1, 1, device=device)\n",
        "            fake_images = generator(noise)\n",
        "            outputs_fake = discriminator(fake_images.detach())\n",
        "            labels.fill_(0)\n",
        "            loss_fake = criterion_d(outputs_fake, labels)\n",
        "            loss_fake.backward()\n",
        "            d_loss = loss_fake + loss_real\n",
        "            optimizer_d.step()\n",
        "\n",
        "            # Train generator\n",
        "            optimizer_g.zero_grad()\n",
        "            outputs = discriminator(fake_images)\n",
        "            loss_generator = criterion_d(outputs, labels)\n",
        "            loss_generator.backward()\n",
        "            g_loss = loss_generator\n",
        "            optimizer_g.step()\n",
        "\n",
        "            outputs = generator(noise)\n",
        "            predictions = net(outputs)\n",
        "            predicted_labels = torch.max(predictions, dim=1).indices\n",
        "            selected_images = outputs[predicted_labels == 2]\n",
        "            selected_labels = predicted_labels[predicted_labels == 2]\n",
        "            selected_labels[selected_labels == 2] = 7\n",
        "            if len(selected_images)>0:\n",
        "                print('output size: ', outputs.size(0))\n",
        "                print('selected images size: ', selected_images.size(0))\n",
        "                optimizer_net.zero_grad()\n",
        "                outputs = net(selected_images)\n",
        "                loss = criterion(outputs, selected_labels)\n",
        "                loss.backward()\n",
        "                for param in net.parameters():\n",
        "                    param.grad *= 1\n",
        "                optimizer_net.step()\n",
        "        scheduler_net.step()\n",
        "        # scheduler_g.step()\n",
        "        # scheduler_d.step()\n",
        "    save_folder = \"content/images\"\n",
        "\n",
        "    # Tạo thư mục nếu nó chưa tồn tại\n",
        "    os.makedirs(save_folder, exist_ok=True)\n",
        "    plot_generated(generator, save_folder, num_images=16, device=device)"
      ],
      "metadata": {
        "id": "yVvWCzXUgiv-"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FlowerClient(FlowerClient):\n",
        "    def fit(self, parameters, config):\n",
        "        \"\"\"This method train the model using the parameters sent by the\n",
        "        server on the dataset of this client. At then end, the parameters\n",
        "        of the locally trained model are communicated back to the server\"\"\"\n",
        "        # print(f\"[Client {self.cid}] fit, config: {config}\")\n",
        "        # copy parameters sent by the server into client's local model\n",
        "        self.set_parameters(parameters)\n",
        "        lr, epochs = config[\"lr\"], config[\"epochs\"]\n",
        "\n",
        "        optimizer_net = torch.optim.SGD(self.model.parameters(), lr=lr)\n",
        "        criterion = torch.nn.CrossEntropyLoss()\n",
        "        scheduler_net = lr_scheduler.StepLR(optimizer_net, step_size=2, gamma=0.1)\n",
        "        i = 0\n",
        "        if self.cid in [0, 1, 2]:\n",
        "            print('ATTACKER')\n",
        "            attacker_lr, attacker_epochs = config[\"attacker_lr\"], config[\"attacker_epochs\"]\n",
        "            loss, accuracy = test(self.model, self.testloader, device=self.device)\n",
        "            criterion_d = torch.nn.BCELoss()\n",
        "            optimizer_g = torch.optim.Adam(self.generator.parameters(), lr=0.002, betas=(0.5, 0.999))\n",
        "            scheduler_g = lr_scheduler.StepLR(optimizer_g, step_size=2, gamma=0.1)\n",
        "            optimizer_d = torch.optim.Adam(self.discriminator.parameters(), lr=0.002, betas=(0.5, 0.999))\n",
        "            scheduler_d = lr_scheduler.StepLR(optimizer_d, step_size=2, gamma=0.1)\n",
        "\n",
        "            if accuracy > 60:\n",
        "                train(net=self.model, trainloader=self.trainloader, optim=optimizer_net, scheduler=scheduler_net, criterion=criterion, epochs=epochs, device=self.device)\n",
        "                poisontrain(self.model, self.generator, self.discriminator, self.trainloader,\n",
        "                          optimizer_net, optimizer_g, optimizer_d,\n",
        "                          scheduler_net, scheduler_g, scheduler_d,\n",
        "                          criterion, criterion_d, attacker_epochs, self.device)\n",
        "            else:\n",
        "                poisontrain(self.model, self.generator, self.discriminator, self.trainloader,\n",
        "                          optimizer_net, optimizer_g, optimizer_d,\n",
        "                          scheduler_net, scheduler_g, scheduler_d,\n",
        "                          criterion, criterion_d, attacker_epochs, self.device)\n",
        "        else:\n",
        "            train(net=self.model, trainloader=self.trainloader, optim=optimizer_net, scheduler=scheduler_net, criterion=criterion, epochs=epochs, device=self.device)\n",
        "\n",
        "        # return the model parameters to the server as well as extra info (number of training examples in this case)\n",
        "        return self.get_parameters({}), len(self.trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters: NDArrays, config: Dict[str, Scalar]):\n",
        "        \"\"\"Evaluate the model sent by the server on this client's\n",
        "        local validation set. Then return performance metrics.\"\"\"\n",
        "\n",
        "        self.set_parameters(parameters)\n",
        "        loss, accuracy = test(self.model, self.valloader, device=self.device)\n",
        "\n",
        "        return float(loss), len(self.valloader), {\"accuracy\": accuracy}"
      ],
      "metadata": {
        "id": "UYzulLVecDhh"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "net = Net(10)\n",
        "# list_of_files = [fname for fname in glob.glob(\"./model_round_*\")]\n",
        "# latest_round_file = max(list_of_files, key=os.path.getctime)\n",
        "latest_round_file = './model_round_df.pth'\n",
        "print(\"Loading pre-trained model from: \", latest_round_file)\n",
        "state_dict = torch.load(latest_round_file)\n",
        "net.load_state_dict(state_dict)"
      ],
      "metadata": {
        "id": "nMbxpOIuciXY",
        "outputId": "5e91b207-2e3c-4466-a64b-f79e9cb4af5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading pre-trained model from:  ./model_round_df.pth\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_parameters():\n",
        "    \"\"\"Extract all model parameters and conver them to a list of\n",
        "    NumPy arryas. The server doesn't work with PyTorch/TF/etc.\"\"\"\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()]"
      ],
      "metadata": {
        "id": "DAGYFxwKnosX"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = get_parameters()\n",
        "\n",
        "strategy = SaveModelStrategy(\n",
        "    fraction_fit=0.31,  # Sample 10% of available clients for training\n",
        "    fraction_evaluate=0.31,  # Sample 5% of available clients for evaluation\n",
        "    on_fit_config_fn=fit_config,\n",
        "    evaluate_metrics_aggregation_fn=weighted_average,  # aggregates federated metrics\n",
        "    evaluate_fn=get_evaluate_fn(centralized_testset),  # global evaluation function\n",
        "    initial_parameters=fl.common.ndarrays_to_parameters(params),\n",
        ")"
      ],
      "metadata": {
        "id": "3Hx55QIkdjce"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# With a dictionary, you tell Flower's VirtualClientEngine that each\n",
        "# client needs exclusive access to these many resources in order to run\n",
        "client_resources = {\"num_cpus\": 2, \"num_gpus\": 1}\n",
        "\n",
        "# Let's disable tqdm progress bar in the main thread (used by the server)\n",
        "disable_progress_bar()\n",
        "history = fl.simulation.start_simulation(\n",
        "    client_fn=client_fn_callback,  # a callback to construct a client\n",
        "    num_clients=NUM_CLIENTS,  # total number of clients in the experiment\n",
        "    config=fl.server.ServerConfig(num_rounds=50),  # let's run for 10 rounds\n",
        "    strategy=strategy,  # the strategy that will orchestrate the whole FL pipeline\n",
        "    client_resources=client_resources,\n",
        "    actor_kwargs={\n",
        "        \"on_actor_init_fn\": disable_progress_bar  # disable tqdm on each actor/process spawning virtual clients\n",
        "    },\n",
        ")"
      ],
      "metadata": {
        "id": "kFfMZwVVchgj",
        "outputId": "80f4e6fa-8931-4ed4-de88-55e260a8d038",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flwr 2024-01-19 17:09:44,376 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=50, round_timeout=None)\n",
            "INFO:flwr:Starting Flower simulation, config: ServerConfig(num_rounds=50, round_timeout=None)\n",
            "2024-01-19 17:09:47,321\tINFO worker.py:1621 -- Started a local Ray instance.\n",
            "INFO flwr 2024-01-19 17:09:51,094 | app.py:213 | Flower VCE: Ray initialized with resources: {'object_store_memory': 3840954777.0, 'memory': 7681909556.0, 'node:172.28.0.12': 1.0, 'GPU': 1.0, 'node:__internal_head__': 1.0, 'CPU': 2.0}\n",
            "INFO:flwr:Flower VCE: Ray initialized with resources: {'object_store_memory': 3840954777.0, 'memory': 7681909556.0, 'node:172.28.0.12': 1.0, 'GPU': 1.0, 'node:__internal_head__': 1.0, 'CPU': 2.0}\n",
            "INFO flwr 2024-01-19 17:09:51,097 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html\n",
            "INFO:flwr:Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html\n",
            "INFO flwr 2024-01-19 17:09:51,107 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 2, 'num_gpus': 1}\n",
            "INFO:flwr:Flower VCE: Resources for each Virtual Client: {'num_cpus': 2, 'num_gpus': 1}\n",
            "INFO flwr 2024-01-19 17:09:51,171 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 1 actors\n",
            "INFO:flwr:Flower VCE: Creating VirtualClientEngineActorPool with 1 actors\n",
            "INFO flwr 2024-01-19 17:09:51,183 | server.py:89 | Initializing global parameters\n",
            "INFO:flwr:Initializing global parameters\n",
            "INFO flwr 2024-01-19 17:09:51,186 | server.py:272 | Using initial parameters provided by strategy\n",
            "INFO:flwr:Using initial parameters provided by strategy\n",
            "INFO flwr 2024-01-19 17:09:51,196 | server.py:91 | Evaluating initial parameters\n",
            "INFO:flwr:Evaluating initial parameters\n",
            "\u001b[2m\u001b[36m(pid=16603)\u001b[0m 2024-01-19 17:10:05.849478: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=16603)\u001b[0m 2024-01-19 17:10:05.849540: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=16603)\u001b[0m 2024-01-19 17:10:05.851318: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=16603)\u001b[0m 2024-01-19 17:10:11.668276: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "INFO flwr 2024-01-19 17:10:21,210 | server.py:94 | initial parameters (loss, other metrics): 311.81925106048584, {'accuracy': 0.1937984496124031}\n",
            "INFO:flwr:initial parameters (loss, other metrics): 311.81925106048584, {'accuracy': 0.1937984496124031}\n",
            "INFO flwr 2024-01-19 17:10:21,217 | server.py:104 | FL starting\n",
            "INFO:flwr:FL starting\n",
            "DEBUG flwr 2024-01-19 17:10:21,221 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:fit_round 1: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GLOBAL TEST\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m ATTACKER\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m selected images size:  9\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m ATTACKER\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m   warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m ATTACKER\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m selected images size:  1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2024-01-19 17:13:59,088 | server.py:236 | fit_round 1 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 1 received 10 results and 0 failures\n",
            "WARNING flwr 2024-01-19 17:13:59,162 | fedavg.py:242 | No fit_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No fit_metrics_aggregation_fn provided\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving round 1 aggregated_parameters...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flwr 2024-01-19 17:14:14,668 | server.py:125 | fit progress: (1, 311.8099219799042, {'accuracy': 0.1937984496124031}, 233.44742663499983)\n",
            "INFO:flwr:fit progress: (1, 311.8099219799042, {'accuracy': 0.1937984496124031}, 233.44742663499983)\n",
            "DEBUG flwr 2024-01-19 17:14:14,672 | server.py:173 | evaluate_round 1: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:evaluate_round 1: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2024-01-19 17:14:19,293 | server.py:187 | evaluate_round 1 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 1 received 10 results and 0 failures\n",
            "DEBUG flwr 2024-01-19 17:14:19,296 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:fit_round 2: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m ATTACKER\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m selected images size:  16\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m selected images size:  7\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m selected images size:  2\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m output size:  101\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m selected images size:  2\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m selected images size:  3\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2024-01-19 17:16:22,686 | server.py:236 | fit_round 2 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 2 received 10 results and 0 failures\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving round 2 aggregated_parameters...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flwr 2024-01-19 17:16:38,942 | server.py:125 | fit progress: (2, 311.77008605003357, {'accuracy': 0.1937984496124031}, 377.721021887)\n",
            "INFO:flwr:fit progress: (2, 311.77008605003357, {'accuracy': 0.1937984496124031}, 377.721021887)\n",
            "DEBUG flwr 2024-01-19 17:16:38,945 | server.py:173 | evaluate_round 2: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:evaluate_round 2: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2024-01-19 17:16:42,346 | server.py:187 | evaluate_round 2 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 2 received 10 results and 0 failures\n",
            "DEBUG flwr 2024-01-19 17:16:42,352 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:fit_round 3: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m ATTACKER\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m selected images size:  2\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m selected images size:  2\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m selected images size:  6\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m selected images size:  3\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2024-01-19 17:18:44,946 | server.py:236 | fit_round 3 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 3 received 10 results and 0 failures\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving round 3 aggregated_parameters...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flwr 2024-01-19 17:19:00,415 | server.py:125 | fit progress: (3, 311.7689872980118, {'accuracy': 0.1937984496124031}, 519.1940587059999)\n",
            "INFO:flwr:fit progress: (3, 311.7689872980118, {'accuracy': 0.1937984496124031}, 519.1940587059999)\n",
            "DEBUG flwr 2024-01-19 17:19:00,418 | server.py:173 | evaluate_round 3: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:evaluate_round 3: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2024-01-19 17:19:03,809 | server.py:187 | evaluate_round 3 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 3 received 10 results and 0 failures\n",
            "DEBUG flwr 2024-01-19 17:19:03,812 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:fit_round 4: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m ATTACKER\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m selected images size:  66\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m selected images size:  3\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m selected images size:  3\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2024-01-19 17:21:06,848 | server.py:236 | fit_round 4 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 4 received 10 results and 0 failures\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving round 4 aggregated_parameters...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flwr 2024-01-19 17:21:22,288 | server.py:125 | fit progress: (4, 311.7597953081131, {'accuracy': 0.1937984496124031}, 661.0671123419997)\n",
            "INFO:flwr:fit progress: (4, 311.7597953081131, {'accuracy': 0.1937984496124031}, 661.0671123419997)\n",
            "DEBUG flwr 2024-01-19 17:21:22,293 | server.py:173 | evaluate_round 4: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:evaluate_round 4: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2024-01-19 17:21:25,700 | server.py:187 | evaluate_round 4 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 4 received 10 results and 0 failures\n",
            "DEBUG flwr 2024-01-19 17:21:25,704 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:fit_round 5: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m ATTACKER\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m selected images size:  49\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m selected images size:  6\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m ATTACKER\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m selected images size:  11\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m selected images size:  1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2024-01-19 17:24:11,146 | server.py:236 | fit_round 5 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 5 received 10 results and 0 failures\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving round 5 aggregated_parameters...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flwr 2024-01-19 17:24:25,992 | server.py:125 | fit progress: (5, 311.7764347791672, {'accuracy': 0.1937984496124031}, 844.770729369)\n",
            "INFO:flwr:fit progress: (5, 311.7764347791672, {'accuracy': 0.1937984496124031}, 844.770729369)\n",
            "DEBUG flwr 2024-01-19 17:24:25,995 | server.py:173 | evaluate_round 5: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:evaluate_round 5: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2024-01-19 17:24:29,337 | server.py:187 | evaluate_round 5 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 5 received 10 results and 0 failures\n",
            "DEBUG flwr 2024-01-19 17:24:29,340 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:fit_round 6: strategy sampled 10 clients (out of 33)\n",
            "DEBUG flwr 2024-01-19 17:25:42,198 | server.py:236 | fit_round 6 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 6 received 10 results and 0 failures\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving round 6 aggregated_parameters...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flwr 2024-01-19 17:25:56,861 | server.py:125 | fit progress: (6, 311.77242600917816, {'accuracy': 0.1937984496124031}, 935.6400143390001)\n",
            "INFO:flwr:fit progress: (6, 311.77242600917816, {'accuracy': 0.1937984496124031}, 935.6400143390001)\n",
            "DEBUG flwr 2024-01-19 17:25:56,871 | server.py:173 | evaluate_round 6: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:evaluate_round 6: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2024-01-19 17:26:00,182 | server.py:187 | evaluate_round 6 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 6 received 10 results and 0 failures\n",
            "DEBUG flwr 2024-01-19 17:26:00,187 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:fit_round 7: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m ATTACKER\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2024-01-19 17:27:58,360 | server.py:236 | fit_round 7 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 7 received 10 results and 0 failures\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving round 7 aggregated_parameters...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flwr 2024-01-19 17:28:13,351 | server.py:125 | fit progress: (7, 311.74642848968506, {'accuracy': 0.1937984496124031}, 1072.1305215780003)\n",
            "INFO:flwr:fit progress: (7, 311.74642848968506, {'accuracy': 0.1937984496124031}, 1072.1305215780003)\n",
            "DEBUG flwr 2024-01-19 17:28:13,355 | server.py:173 | evaluate_round 7: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:evaluate_round 7: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2024-01-19 17:28:17,113 | server.py:187 | evaluate_round 7 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 7 received 10 results and 0 failures\n",
            "DEBUG flwr 2024-01-19 17:28:17,118 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 33)\n",
            "DEBUG:flwr:fit_round 8: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m ATTACKER\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m selected images size:  18\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=16603)\u001b[0m selected images size:  8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(main_acc_values))\n",
        "global_accuracy_centralised = history.metrics_centralized[\"accuracy\"]\n",
        "global_accuracy_distributed = history.metrics_distributed[\"accuracy\"]\n",
        "\n",
        "# Rút trích thông tin từ dữ liệu\n",
        "# round_centralised = [data[0] for data in global_accuracy_centralised]\n",
        "round_distributed = [data[0] for data in global_accuracy_distributed]\n",
        "\n",
        "# Vẽ đồ thị\n",
        "plt.plot(range(1, 52), [data[1] for data in global_accuracy_centralised], label=\"Global - Centralised\")\n",
        "# plt.plot(range(1, 21), [data[1] for data in global_accuracy_distributed], label=\"Global - Distributed\")\n",
        "plt.plot(range(1, 52), main_acc_values, label=\"Main Task\")\n",
        "plt.plot(range(1, 52), standard_acc_values, label=\"Standard Task\")\n",
        "\n",
        "# Thiết lập định dạng của biểu đồ\n",
        "plt.grid()\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.xlabel(\"Round\")\n",
        "plt.title(\"Accuracy Comparison\")\n",
        "plt.legend()\n",
        "xticks_result = plt.xticks(range(1, 52))\n"
      ],
      "metadata": {
        "id": "E33BylpJA_CV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(f\"{history.metrics_centralized = }\")\n",
        "# print(f\"{history.metrics_distributed = }\")\n",
        "\n",
        "\n",
        "global_accuracy_centralised = history.metrics_centralized[\"accuracy\"]\n",
        "# global_accuracy_centralised = history.metrics_distributed[\"accuracy\"]\n",
        "\n",
        "round = [data[0] for data in global_accuracy_centralised]\n",
        "acc = [data[1] for data in global_accuracy_centralised]\n",
        "plt.plot(round, acc)\n",
        "plt.grid()\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.xlabel(\"Round\")\n",
        "plt.title(\"MNIST - IID - 30 clients with 10 clients per round\")\n",
        "xticks_result = plt.xticks(range(1, 21))\n",
        "# plt.yticks(range(0, 100))"
      ],
      "metadata": {
        "id": "NECbOpWgcxdV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}